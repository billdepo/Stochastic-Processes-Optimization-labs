{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Stochastic_Processes_&_Optimization_in_Machine_Learning_(Lab_10_DNS_Water_Torture).ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLUCLr2dsyWQ"
   },
   "source": [
    "<b><h1>DNS Water Torture σε Recursive DNS Servers</h1></b>\n",
    "\n",
    "<p align=\"justify\">Στην άσκηση αυτή, θα αναπτύξετε ένα μηχανισμό αντιμετώπισης επιθέσεων <i>DNS Water Torture</i> σε <i>Recursive DNS Servers</i> (δίνεται <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab10/Lab_theory\">υποστηρικτικό υλικό</a> για την άσκηση). Ουσιαστικά, το πρόβλημα αυτό είναι ένα πρόβλημα text classification που έγγειται στο διαχωρισμό ονομάτων DNS που είναι <i>έγκυρα (valid)</i> και <i>άκυρα (invalid)</i>. </p>\n",
    "\n",
    "<p align=\"justify\">Με τη βοήθεια του αλγορίθμου Naive Bayes Classifier, θα διαχωρίσετε τα prefixes των <i>ονομάτων DNS</i> σε <i>έγκυρα</i> και <i>άκυρα</i>. Στην άσκηση αυτή, ως <i>prefix</i> ορίζουμε το <i>πρώτο label</i> ενός <i>ονόματος DNS</i>. Για παράδειγμα, το prefix του ονόματος www.ntua.gr είναι το <i>www</i>, ενώ το prefix του ονόματος dolly.netmode.ece.ntua.gr είναι το <i>dolly</i>.</p>\n",
    "\n",
    "<p align=\"justify\">Ο αλγόριθμος θα εκπαιδευτεί με <u>έγκυρα ονόματα</u> (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/valid_training.txt\">valid_training.txt</a>) και άκυρα ονόματα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/invalid_training.txt\">invalid_training.txt</a>). Η δοκιμή του θα γίνει στο <u>test set</u>, που περιλαμβάνει, επίσης, έγκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/valid_test.txt\">valid_test.txt</a>) και άκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/invalid_test.txt\">invalid_test.txt</a>) ονόμάτα.</p>\n",
    "\n",
    "<p align=\"justify\">Να απαντήσετε στις ακόλουθες ερωτήσεις:</p>\n",
    "<ul>\n",
    "<li>Ποια είναι η παραδοχή του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>; Ποια είναι τα πλεονεκτήματα του αλγορίθμου;</li>\n",
    "<li>Να περιγράψετε σύντομα τη λειτουργία του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>.</li>\n",
    "<li>Μελετήστε τα prefixes που περιλαμβάνονται στα αρχεία <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/valid_training.txt\">valid_training.txt</a> και <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/invalid_training.txt\">invalid_training.txt</a>. Σχολιάστε μερικές από τις βασικές διαφορές ανάμεσα στα prefixes των δύο αρχείων που θα μπορούσαν να φανούν χρήσιμες για το διαχωρισμό των έγκυρων και των άκυρων ονομάτων.</li>\n",
    "<li>Ποια είναι τα 7 features που έχουν επιλεχθεί στον κώδικα της άσκησης;</li>\n",
    "<li>Να εκτελέσετε τον κώδικα της άσκησης. Καταγράψετε και σχολιάστε την ακρίβεια του αλγορίθμου πάνω στο <i>test set</i> για τα valid και τα invalid names ξεχωριστά. Ποιο είναι το μέγεθος του <i>training set</i>; Πόση ώρα διήρκησε η εκπαίδευση του αλγορίθμου;</li>\n",
    "<li>Αφού εκτελέσετε τον κώδικα, θα παρατηρήσετε πως έχουν παραχθεί δύο αρχεία: <i>problematic_valid.txt</i> και <i>problematic_invalid.txt</i>. Μελετώντας τον κώδικα, γιατί πιστεύετε ότι τα prefixes που περιλαμβάνονται σε αυτά τα αρχεία δημιουργούν πρόβλημα στην περίπτωσή μας; Θυμηθείτε τα μειονεκτήματα του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>. Τι θα μπορούσατε να κάνετε για να λύσετε το πρόβλημα αυτό (<a href=\"https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf\">https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf</a>);</li>\n",
    "<li>Μελετώντας τη συνάρτηση <i>find_prob()</i>, θα δείτε πως λείπουν οι πιθανότητες <i>prior</i> από τους υπολογισμούς. Τι παραδοχή έχουμε κάνει για τις <i>prior</i> πιθανότητες και κατά συνέπεια για τις δύο κατηγορίες ταξινόμησης (<i>valid</i>, <i>invalid</i>) στην άσκησή μας; Πώς αλλιώς θα μπορούσατε να τις επιλέξετε;</li>\n",
    "<li>Μπορείτε να προτείνετε κάποιο επιπρόσθετο <i>feature</i> για τον αλγόριθμο; (δε χρειάζεται να το υλοποιήσετε)</li>\n",
    "</ul>\n",
    "\n",
    "<p align=\"justify\"><b>Πηγές Δεδομένων</b></p>\n",
    "<ul>\n",
    "<li>Valid ονόματα: <a href=\"https://www.kaggle.com/cheedcheed/top1m\">https://www.kaggle.com/cheedcheed/top1m</a> (πολλά από τα κορυφαία σε επισκεψιμότητα site)</li>\n",
    "<li>Invalid ονόματα: Παράχθηκαν με το πρόγραμμα <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab10/generator.py\">generator.py</a> που θα βρείτε μαζί με τα υπόλοιπα αρχεία της άσκησης.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 1\n",
    ">Ποια είναι η παραδοχή του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>; Ποια είναι τα πλεονεκτήματα του αλγορίθμου;\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Η βασική παραδοχή του Naive Bayes Classifier είναι πως τα χαρακτηριστικά (features) είναι ανεξάρτητα (independent) δεδομένης της κλάσης, δηλαδή $P(\\omega_k|\\vec{x}) \\propto \\prod_{i=1}^{d} p(x_i|\\omega_k) $ κάτι το οποίο φυσικά δεν είναι αληθές σε πολλά προβλήματα. Αυτή η αφελής/naive υπόθεση έδωσε και το όνομα της στον ταξινομητή που βασίζεται επίσης στον κανόνα του Bayes.\n",
    "\n",
    "Ωστόσο, ο αλγόριθμος εναι εύκολος στην υλοποίηση και γρήγορος για πολύ μεγάλα datasets με μεγάλο dimensionality ενώ δεν είναι ευαίσθητος στο θόρυβο. Xρησιμοποιείται σε εφαμογές όπως spam filtering, sentiment analysis, recommendation systems κ.α.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 2\n",
    ">Να περιγράψετε σύντομα τη λειτουργία του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Εν γένει ο αλγόριθμος κάνει process το training dataset για να υπολογίσει για κάθε κλάση $\\omega_k$, τις πιθανότητες ένα δειγματικό στοιχείο $\\vec{x}$ να ανήκει στην κλάση αυτή: ως: $P(\\omega_k|\\vec{x}) = P(\\omega_k) \\cdot \\frac{\\prod_{i=1}^{d} p(x_i|\\omega_k) }{\\prod_{i=1}^{d} P(x_i) }    \\propto \\prod_{i=1}^{d} p(x_i|\\omega_k) $\n",
    "\n",
    "Τελικά, ένα δειγματικό στοιχείο $\\vec{x}$ ταξινομείται στην κλάση $\\omega_k$ με τη μεγαλύτερη πιθανότητα $P(\\omega_k|\\vec{x})$. Για συνεχή χαρακτηριστικά συνήθω υποθέτουμε ότι η κατανομή των features είναι κανονική κατανομή.  Έτσι, για κάθε κλάση ξεχωριστά υπολογίζουμε τις παραμέτρους μιας κανονικής κατανομής με βάση το training dataset, για να μπορούμε στη συνέχεια να υπολογίσουμε την πιθανοφάνεια $p(x_i|\\omega_k)$. Πχ. για κανονική κατανομή με μέση τιμή $μ$ και τυπική απόκλιση $σ$, έχουμε:\n",
    "$p(x_i|\\omega_k) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{1}{2}(\\frac{x-μ}{σ})^2)$ και ο αλγόριθμος τελικά διαλέγει την κατηγορία $\\omega_j$ που μεγιστοποιεί την ποσότητα $P(\\omega_k) \\prod_{i=1}^{d} p(x_i|\\omega_k)$, το οποίο ονομάζεται maximum posterior decision rule και εκφράζει την επιλογή της πιο πιθανούς υπόθεσης."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 3\n",
    ">Μελετήστε τα prefixes που περιλαμβάνονται στα αρχεία <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/valid_training.txt\">valid_training.txt</a> και <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/invalid_training.txt\">invalid_training.txt</a>. Σχολιάστε μερικές από τις βασικές διαφορές ανάμεσα στα prefixes των δύο αρχείων που θα μπορούσαν να φανούν χρήσιμες για το διαχωρισμό των έγκυρων και των άκυρων ονομάτων."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Αρχικά, παρατηρούμε πως για το `invalid_training.txt` πολλά από τα prefixes που δίνονται εκκινούν με αριθμητικό χαρακτήρασ, κάτι το οποίο δε συμβαίνει στο `valid_training.txt`.\n",
    "Ακόμη, τα invalid prefixes φαίνονται να έχουν εν γένει μεγαλύτερο μήκος, όπως επίσης τα invalid prefixes περιέχουν πολλά περισσότερα σύμφωνα, καθώς από τα 26 γράμματα του λατινικού αλφαβήτου μόνο 5 εξ αυτών είναι φωνήεντα, ενώ κάθε φορά για την κατασκευή ενός invalid prefix επιλέγεται τυχαία ένα εκ των 26 γραμμάτων."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 4\n",
    ">Ποια είναι τα 7 features που έχουν επιλεχθεί στον κώδικα της άσκησης;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Τα 7 χαρακτηριστικά που επιλέχθηκαν στον κώδικα εξάγονται από τη συνάρτηση `handle_name` και είναι τα εξής:\n",
    "- `total_length`: μήκος σε χαρακτήρες του prefix\n",
    "- `total_digits`: συνολικός αριθμός αριθμητικών χαρακτήρων στο prefix\n",
    "- `max_numeric_sequence`: μέγιστο μήκος σειράς απο διαδοχικούς αριθμούς εντός του prefix\n",
    "- `total_consonants`: συνολικό αριθμός από σύμφωνα στο prefix\n",
    "- `max_consonants_sequence`: μέγιστο μήκος σειράς απο διαδοχικά σύμφωνα εντός του prefix\n",
    "- `total_vowels`: συνολικό αριθμός από φωνήεντα στο prefix\n",
    "- `max_vowels_sequence`: μέγιστο μήκος σειράς απο διαδοχικά φωνήεντα εντός του prefix\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 5\n",
    ">Να εκτελέσετε τον κώδικα της άσκησης. Καταγράψετε και σχολιάστε την ακρίβεια του αλγορίθμου πάνω στο <i>test set</i> για τα valid και τα invalid names ξεχωριστά. Ποιο είναι το μέγεθος του <i>training set</i>; Πόση ώρα διήρκησε η εκπαίδευση του αλγορίθμου;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Τρέχοντας τον κώδικα, βλέπουμε πως το 1.92% μόνο των valid test δειγματικών στοιχείων γίνονται misclassified ενώ το 1.27% των invalid test δειγματικών στοιχείων αντιστοίχως γίνονται misclassified.\n",
    "Δηλαδή:\n",
    "- $FNR / miss \\ rate = \\frac{FN}{TP+FN} = 1.92\\% \\Rightarrow Recall/sensitivity/TPR = \\frac{TP}{TP+FN} = 1 - FNR = 98.08 \\%$και\n",
    "- $ FPR / probability \\ of \\ false \\ alarm= \\frac{FP}{FP+TN}= 1.27\\% \\Rightarrow Specificity/TNR = \\frac{TN}{FP+TN} = 1-FPR = 98.73\\%$.\n",
    "\n",
    "Είναι πρόδηλο από τα παραπάνω πως ο αλγόριθμος καταφέρνει να διαχωρίσει με μεγάλη ακρίβεια τις δύο κλάσεις.\n",
    "\n",
    "Για την εύρεση του χρόνου εκπαίδευσης χρησιμοποιήσαμε την εντολή `%%timeit` στο κελί με τις εντολές για την εκπαίδευση του ταξινομητή. Βλέπουμε ότι ο χρόνος εκπαίδευσης είναι αρκετά μεγάλος, περίπου μισό λεπτό, κάτι όμως που είναι απόρροια του μεγέθους του training dataset δεδομένου ότι τα `valid_training.txt` και `invalid_training.txt` περιέχουν 1,400,000 εγγραφές από prefixes συνολικά (700,000 κάθε txt αρχείο).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 6\n",
    ">Αφού εκτελέσετε τον κώδικα, θα παρατηρήσετε πως έχουν παραχθεί δύο αρχεία: <i>problematic_valid.txt</i> και <i>problematic_invalid.txt</i>. Μελετώντας τον κώδικα, γιατί πιστεύετε ότι τα prefixes που περιλαμβάνονται σε αυτά τα αρχεία δημιουργούν πρόβλημα στην περίπτωσή μας; Θυμηθείτε τα μειονεκτήματα του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>. Τι θα μπορούσατε να κάνετε για να λύσετε το πρόβλημα αυτό (<a href=\"https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf\">https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf</a>);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Στα δύο αυτά αρχεία περιέχονται τα prefixes που γίνονται misclassified:\n",
    "- Στο `problematic_valid.txt` γράφονται τα prefixes που είναι valid αλλά ο ταξινομητής Naive Bayes προέβλεψε ως invalid.\n",
    "- Στο `problematic_invalid.txt` γράφονται τα prefixes που είναι invalid αλλά ο ταξινομητής Naive Bayes προέβλεψε ως valid.\n",
    "\n",
    "Ουσιαστικά, όπως φαίνεται στη συνάρτηση υπολογισμού της πιθανότητας `find_prob`, αυτή υπολογίζεται ως το γινόμενο $\\prod_{i=1}^{7} p(x_i|\\omega_k) $, όπου $(x_1, x_2, ..., x_7)$ οι τιμές των χαρακτηριστικών ενός prefix. Αυτό το γινόμενο, πέρα από την ανεξαρτησία των features, υπονοεί επίσης ότι το βάρος/συνεισφορρά κάθε χαρακτηριστικού είναι ίδια στον υπολογισμό της πιθανότητας αυτής. Επομένως, αν κάποιο χαρακτηριστικό έχει μικρή τιμή (η τιμή του οποίου στο συγκεκριμένο πρόβλημα υπολογίζεται από τη σχετική συχνότητα εμφάνισης στο dataset εκπαίδευσης), λόγου χάρη αν βρεθεί κάποιο valid prefix με μικρότερο μήκος από το σύνηθες που ωστόσο ακολουθεί το γενικό pattern των valid δειγματικών στοιχείων εκπαίδευσης για τα υπόλοιπα χααρακτηρικστικά, τότε η πιθανότητα που προκύπτει ως γινόμενο θα λάβει μικρή τιμή και άρα το δειγματικό στοιχείο αυτό θα χαρακτηριστεί λανθασμένα ως invalid. Επομένως, η υπόθεση της ανεξαρτησίας των χαρακτηριστικών οδηγεί σε λανθασμένες προβλέψεις.\n",
    "\n",
    "Μία λύση στο πρόβλημα αυτό θα μπορούσε να δώσε η εφαρμογή Logistic Regression, όπου ενώ υπάρχει συμβατότητα με τις υποθέσεις του Naive Bayes classifier ως προς την ανεξαρτησία των χαρακτηριστικών δεδομένης μιας κλάσης, εντούτοις δεν είναι τόσο αυστηρή υπόθεση για τη Logistic Regression. Αν υπάρχουν δεδομένα που δεν υπακούουν στη συνθήκη αυτή, τότε η Logistic Regression προσαρμόζει τις παραμέτρους της κατάλληλα ώστε να μεγιστοποιήσει τη δεσμευμένη πιθανοφάνεια των δεδομένων, ακόμη και αν οι προκύπτουσες παράμετροι δεν είναι συμβατοί με τις κατά Naive Bayes υπολογισμένες παραμέτρους.\n",
    "\n",
    "Η Logistic Regression αναμένεται να κάνει outperform τoν Naive Bayes classifier σε αυτό το πρόβλημα όπου το training set είναι μεγάλο σε μέγεθος, ωστόσο ο χρόνος εκπαίδευσης για τη Logistic Regression είναι μεγαλύτερος."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 7\n",
    ">Μελετώντας τη συνάρτηση <i>find_prob()</i>, θα δείτε πως λείπουν οι πιθανότητες <i>prior</i> από τους υπολογισμούς. Τι παραδοχή έχουμε κάνει για τις <i>prior</i> πιθανότητες και κατά συνέπεια για τις δύο κατηγορίες ταξινόμησης (<i>valid</i>, <i>invalid</i>) στην άσκησή μας; Πώς αλλιώς θα μπορούσατε να τις επιλέξετε;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Οι πιθανότες priors $P(\\omega_k)$ για $k=1,2$ (κλάσεις valid και invalid) λείπουν καθώς έχει υποτεθεί ότι αυτές είναι ίσες, δηλαδή ότι η πιθανότητα ένα οποιοδήποτε δειγματικό στοιχείο να ανήκει στην valid ή invalid κλάση είναι ίση με $0.5$ και για τις δύο κλάσεις.\n",
    "\n",
    "Οι πιθανότητες αυτές συνήθως επιλέγονται με βάση των αριθμό δειγματικών στοιχείων στο training set της κάθε κλάσης ως προς το σύνολό τους. Εδώ έχουμε από $700,000$ δειγματικά στοιχεία εκπαίδευσης στα `valid_training.txt` και `invalid_training.txt`, επομένως με αυτή τη μέθοδο οι priors προκύπτουν ως $0.5$.\n",
    "\n",
    "Ωστόσο, θα μπορούσαν να επιλεχθούν διαφορετικά οι priors, γνωρίζοντας καλύτερα το πρόβλημα στο οποίο αναφερόμαστε και την πιθανότητα invalid prefix στη γενική περίπτωση. Αυτή ενδεχομένως να αναμέναμε να είναι μικρότερη από ένα valid prefix οπότε οι priors θα ήταν διαφορετικές. Για την κατάλληλη επιλογή των τιμών αυτών απαιτείται βιβλιογραφική αναζήτηση."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 8\n",
    ">Μπορείτε να προτείνετε κάποιο επιπρόσθετο <i>feature</i> για τον αλγόριθμο; (δε χρειάζεται να το υλοποιήσετε)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Στο αρχείο `problematic_invalid.txt`, στο οποίο περιέχονται τα prefixes που είναι invalid αλλά ταξινομήθηκαν ως valid από τον NB classifier, παρατηρούμε ότι τα περισσότερα περιέχουν κυρίως consontants/σύμφωνα, όπως έχουμε εξηγήσει προηγουμένως.\n",
    "\n",
    "Στα χαρακτηριστικά ως τώρα έχει συμπεριληφθεί ο συνολικός αριθμός consonants και το μέγιστο μήκος sequence των consonants.\n",
    "Ωστόσο, θα μπορούσαμε να προσθέσουμε λόγου χάρη τον αναμενόμενο αριθμό consonants πριν από την εμφάνιση ενός vowel/φωνηέντου ως επιπρόσθετο χαρακτηριστικό. Αυτό το χαρακτηριστικό ενδεχομένως, θα βελτιώσει τη συμπεριφορά και τα valid misclassified sample points στο `problematic_valid.txt` τα οποία έχουν χαρακτηριστεί λανθασμένα ως invalid."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time elapsed: 31.155200958251953\n",
      "Valid names misclassified as invalid - Ratio:  1.9172947402180884\n",
      "Invalid names misclassified as valid - Ratio:  1.2655821677971868\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "problematic1 = open(\"problematic_valid.txt\", \"w\")\n",
    "problematic2 = open(\"problematic_invalid.txt\", \"w\")\n",
    "\n",
    "def load_file(file_name):\n",
    "    fd = open(file_name, \"r\")\n",
    "    my_set = set()\n",
    "    for prefix in fd:\n",
    "        prefix = prefix.rstrip()\n",
    "        my_set.add(prefix)\n",
    "    return my_set\n",
    "\n",
    "def calculate_probabilities(dataset):\n",
    "    stats = dict()\n",
    "    for index in range(0, 7):\n",
    "        stats[index] = dict()\n",
    "    for prefix in dataset:\n",
    "        features = handle_name(prefix) # extract the 7 features from each prefix in a tuple features = (total_length, total_digits, ...)\n",
    "        for index in range(0, 7):\n",
    "            try:\n",
    "                stats[index][features[index]] += 1\n",
    "            except:\n",
    "                stats[index][features[index]] = 1\n",
    "\n",
    "    dataset_size = len(dataset)\n",
    "    for index in range(0, 7):\n",
    "        for key in stats[index]:\n",
    "            stats[index][key] /= dataset_size\n",
    "    return stats\n",
    "\n",
    "def handle_name(prefix):\n",
    "    total_length = len(prefix)\n",
    "    total_digits, max_numeric_sequence = numeric(prefix)\n",
    "    total_consonants, max_consonants_sequence = consonants(prefix)\n",
    "    total_vowels, max_vowels_sequence = vowels(prefix)\n",
    "    return total_length, total_digits, max_numeric_sequence, total_consonants, max_consonants_sequence, total_vowels, max_vowels_sequence\n",
    "\n",
    "def vowels(prefix):\n",
    "    total_vowels = 0\n",
    "    vowels_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char == 'a' or char == 'e' or char == 'i' or char == 'o' or char == 'u':\n",
    "            total_vowels += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            vowels_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    vowels_sequence.append(current_sequence)\n",
    "    max_vowels_sequence = max(vowels_sequence)\n",
    "    return total_vowels, max_vowels_sequence\n",
    "\n",
    "def consonants(prefix):\n",
    "    total_consonants = 0\n",
    "    consonants_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char != 'a' and char != 'e' and char != 'i' and char != 'o' and char != 'u' and char != '-' and char.isdigit() == False:\n",
    "            total_consonants += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            consonants_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    consonants_sequence.append(current_sequence)\n",
    "    max_consonants_sequence = max(consonants_sequence)\n",
    "    return total_consonants, max_consonants_sequence\n",
    "\n",
    "def numeric(prefix):\n",
    "    total_digits = 0\n",
    "    numeric_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char.isdigit() == True:\n",
    "            total_digits += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            numeric_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    numeric_sequence.append(current_sequence)\n",
    "    max_numeric_sequence = max(numeric_sequence)\n",
    "    return total_digits, max_numeric_sequence\n",
    "\n",
    "def find_prob(prefix, stats, fd):\n",
    "    tl, td, mns, tc, mcs, tv, mvs = handle_name(prefix)\n",
    "    try:\n",
    "        prob = stats[0][tl] * stats[1][td] * stats[2][mns] * stats[3][tc] * stats[4][mcs] * stats[5][tv] * stats[6][mvs]\n",
    "    except:\n",
    "        prob = 0\n",
    "        fd.write(prefix + \"\\n\")\n",
    "    return prob\n",
    "\n",
    "def apply_on_test_set(test_set, category, valid_stats, invalid_stats, fd):\n",
    "    misclassifications = 0\n",
    "    names_processed = 0\n",
    "    for prefix in test_set:\n",
    "        valid_prob = find_prob(prefix, valid_stats, fd)\n",
    "        invalid_prob = find_prob(prefix, invalid_stats, fd)\n",
    "        if valid_prob != 0 and invalid_prob != 0:\n",
    "            names_processed += 1\n",
    "            if category == \"valid\" and valid_prob < invalid_prob:\n",
    "                misclassifications += 1\n",
    "            elif category == \"invalid\" and valid_prob > invalid_prob:\n",
    "                misclassifications += 1\n",
    "    return misclassifications, names_processed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load valid names training set\n",
    "    valid_names_training = load_file(\"./valid_training.txt\")\n",
    "    # Load valid names test set\n",
    "    valid_names_test = load_file(\"./valid_test.txt\")\n",
    "    # Load invalid names training set\n",
    "    invalid_names_training = load_file(\"./invalid_training.txt\")\n",
    "    # Load invalid names test set\n",
    "    invalid_names_test = load_file(\"./invalid_test.txt\")\n",
    "\n",
    "    #training\n",
    "    start_training_time = time.time()\n",
    "    valid_stats = calculate_probabilities(valid_names_training)\n",
    "    invalid_stats = calculate_probabilities(invalid_names_training)\n",
    "    end_training_time = time.time()\n",
    "    print (\"Training time elapsed:\", end_training_time - start_training_time)\n",
    "\n",
    "    valid_misclassifications, valid_names_processed = apply_on_test_set(valid_names_test, \"valid\", valid_stats, invalid_stats, problematic1)\n",
    "    invalid_misclassifications, invalid_names_processed = apply_on_test_set(invalid_names_test, \"invalid\", valid_stats, invalid_stats, problematic2)\n",
    "\n",
    "    print(\"Valid names misclassified as invalid - Ratio: \", (valid_misclassifications / valid_names_processed) * 100)\n",
    "    print(\"Invalid names misclassified as valid - Ratio: \", (invalid_misclassifications / invalid_names_processed) * 100)\n",
    "\n",
    "    problematic1.close()\n",
    "    problematic2.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}