{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DGA_Classification_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Πρόσφατες επιθέσεις, όπως εκείνη στον πάροχο DNS Dyn (<a href=\"https://en.wikipedia.org/wiki/DDoS_attack_on_Dyn\">wiki</a>) αποδεικνύουν ότι ένα από τα σημαντικότερα προβλήματα που αντιμετωπίζει το σύγχρονο Διαδίκτυο είναι εκείνο των botnets. Σε αυτά, ένας επιτιθέμενος συγκεντρώνει την υπολογιστική ισχύ που του είναι απαραίτητη για την εκδήλωση επιθέσεων DDoS ή/και άλλων κακόβουλων δραστηριοτήτων εγκαθιστώντας λογισμικό σε μεγάλο πλήθος από υπολογιστές (bots) που έχουν κενά ασφαλείας (π.χ. συσκευές Internet of Things - IoT).\n",
    "\n",
    "Οι μολυσμένοι υπολογιστές (bots) διατηρούν διαύλους επικοινωνίας με το διαχειριστή του botnet (Command & Control Server) με σκοπό να λαμβάνουν εντολές και να αποστέλλουν πληροφορίες. Για το σκοπό αυτό εκμεταλλεύονται καθιερωμένα πρωτόκολλα, όπως το DNS με την παραγωγή μεγάλου πλήθους από domain names μέσω Domain Generation Algorithms (DGA's) που αλλάζουν διαρκώς για την επικοινωνία του bot με το διαχειριστή του, ώστε να αποφεύγεται ο εντοπισμός του Command & Control Server.\n",
    "\n",
    "Τα ονόματα DNS που χρησιμοποιούνται από αλγορίθμους DGA μπορεί να είναι είτε τυχαία αλφαριθμητικά (π.χ. asdfasjkdfh8oawher8has.com) ή συνδυασμοί τυχαίων λέξεων που έχουν ληφθεί από κάποιο λεξικό (π.χ. school-doctor.com). Χρησιμοποιείται ένας μεγάλος αριθμός από τέτοια ονόματα, η πλειοψηφία των οποίων δεν έχουν κάποια αντιστοίχιση σε διεύθυνση IP και στοχεύουν στην απόκρυψη του Command & Control Server, επειδή οι αμυνόμενοι καλούνται να ελέγξουν κάθε ένα από τα ονόματα που παρατηρούν στο δίκτυό τους, σπαταλώντας χρόνο και πόρους. Επιπρόσθετα, η διεύθυνση IP του Command & Control Server αλλάζει πολύ συχνά (πολλές φορές σε μία μέρα), ώστε να αποφεύγεται ο εντοπισμός του ακόμα και όταν εντοπίζονται τα ονόματα DGA που οδήγησαν σε αυτόν."
   ],
   "metadata": {
    "id": "RczVgvwwHX0h"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab12/dga.png\"></img>"
   ],
   "metadata": {
    "id": "XaN28mnKLHlO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def add_word_distinct_chars(string, distinct_chars):\n",
    "    for char in string:\n",
    "        distinct_chars.add(char)\n",
    "    return distinct_chars\n",
    "\n",
    "def find_max_len(string, max_len):\n",
    "    string_length = len(string)\n",
    "    if string_length > max_len:\n",
    "        max_len = string_length\n",
    "    return max_len\n",
    "\n",
    "def load_data(filename):\n",
    "    dataset = []\n",
    "    distinct_chars = set()\n",
    "    max_len = 0\n",
    "    currentIndex = 0\n",
    "    diverse_labels = dict()\n",
    "    with open(filename, \"r\") as fdr:\n",
    "        for line in fdr:\n",
    "            line = line.strip()\n",
    "            general, label, name = line.split(\",\")\n",
    "            name = name.split(\".\")[0]\n",
    "            if label not in diverse_labels.keys():\n",
    "                diverse_labels[label] = currentIndex\n",
    "                currentIndex += 1\n",
    "            distinct_chars = add_word_distinct_chars(name, distinct_chars)\n",
    "            max_len = find_max_len(name, max_len)\n",
    "            temp_list = []\n",
    "            temp_list.append(name)\n",
    "            temp_list.append(label)\n",
    "            dataset.append(temp_list)\n",
    "    random.shuffle(dataset)\n",
    "    return dataset, distinct_chars, max_len, diverse_labels\n",
    "\n",
    "def assign_index(chars):\n",
    "    features = {}\n",
    "    for index, char in enumerate(chars):\n",
    "        features[char] = index\n",
    "    return features\n",
    "\n",
    "def convert_dataset_and_tokenize(dataset, features, max_len):\n",
    "    for item_no, example in enumerate(dataset):\n",
    "        name = example[0]\n",
    "        label = example[1]\n",
    "        tokenized = []\n",
    "        padding_needed = max_len - len(name)\n",
    "        for index in range(padding_needed):\n",
    "            tokenized.append(0)\n",
    "        for char in name:\n",
    "            token = features[char]\n",
    "            tokenized.append(token)\n",
    "        example[0] = tokenized\n",
    "        dataset[item_no] = example\n",
    "    return dataset\n",
    "\n",
    "def split_examples_labels(dataset):\n",
    "    examples = [entry[0] for entry in dataset]\n",
    "    labels = [entry[1] for entry in dataset]\n",
    "    return examples, labels\n",
    "\n",
    "def convert_labels_to_int(labels, diverse_labels):\n",
    "    for index, label in enumerate(labels):\n",
    "        labels[index] = diverse_labels[label]\n",
    "    return labels\n",
    "\n",
    "def build_model(max_features, max_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128, input_length = max_len))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(26, activation = 'softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def return_fold(examples, labels_int, num_folds, current_fold):\n",
    "    interval = len(examples) // num_folds\n",
    "    current_start = (current_fold - 1) * interval\n",
    "    current_end = current_fold * interval\n",
    "    X_test = examples[current_start:current_end]\n",
    "    y_test = labels_int[current_start:current_end]\n",
    "    X_train = examples[:current_start]\n",
    "    y_train = labels_int[:current_start]\n",
    "    X_train.extend(examples[current_end:])\n",
    "    y_train.extend(labels_int[current_end:])\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def make_predictions(model, X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = numpy.argmax(y_pred, axis = 1)\n",
    "    return y_pred\n",
    "\n",
    "def return_confusion_matrix(y_test, y_pred):\n",
    "    return confusion_matrix(y_test, y_pred)\n",
    "\n",
    "def return_classification_report(y_test, y_pred, diverse_names):\n",
    "    target_names = []\n",
    "    for item in diverse_names.keys():\n",
    "        target_names.append(item)\n",
    "    print(classification_report(y_test, y_pred, target_names = target_names))\n",
    "    return None\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    dataset, distinct_chars, max_len, diverse_labels = load_data(\"dga_domains_full.csv\")\n",
    "    dataset = dataset[0:100000]\n",
    "    max_features = len(distinct_chars) + 1\n",
    "    features = assign_index(distinct_chars)\n",
    "    dataset = convert_dataset_and_tokenize(dataset, features, max_len)\n",
    "    examples, labels = split_examples_labels(dataset)\n",
    "    labels_int = convert_labels_to_int(labels, diverse_labels)\n",
    "\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "    number_of_folds = 5\n",
    "    for fold in range(1, number_of_folds + 1):\n",
    "        X_train, y_train, X_test, y_test = return_fold(examples, labels_int, number_of_folds, fold)\n",
    "        model = build_model(max_features, max_len)\n",
    "        print(\"Training for fold: \", fold)\n",
    "        history = model.fit(X_train, y_train, batch_size = 128, epochs = 5, verbose = 1)\n",
    "        scores = model.evaluate(X_test, y_test, verbose = 1)\n",
    "        print(f'Score for fold {fold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "        y_pred = make_predictions(model, X_test)\n",
    "        print(return_confusion_matrix(y_test, y_pred))\n",
    "        return_classification_report(y_test, y_pred, diverse_labels)\n",
    "\n",
    "    # == Provide average scores ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Score per fold')\n",
    "    for i in range(0, len(acc_per_fold)):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print('Average scores for all folds:')\n",
    "        print(f'> Accuracy: {numpy.mean(acc_per_fold)} (+- {numpy.std(acc_per_fold)})')\n",
    "        print(f'> Loss: {numpy.mean(loss_per_fold)}')\n",
    "        print('------------------------------------------------------------------------')\n"
   ],
   "metadata": {
    "id": "MJMvYAjMK2of",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "04d08971-5721-4bfb-e4e9-a854c5208fd2"
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold:  1\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 220s 347ms/step - loss: 1.4620 - accuracy: 0.6075\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 246s 393ms/step - loss: 0.9428 - accuracy: 0.7139\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 212s 339ms/step - loss: 0.7906 - accuracy: 0.7553\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 194s 310ms/step - loss: 0.7033 - accuracy: 0.7785\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 212s 340ms/step - loss: 0.6417 - accuracy: 0.7950\n",
      "625/625 [==============================] - 27s 39ms/step - loss: 0.5806 - accuracy: 0.8097\n",
      "Score for fold 1: loss of 0.5805745720863342; accuracy of 80.97000122070312%\n",
      "[[ 238    0  155    0    1    0    0    4    0    0    0    0    0    0\n",
      "     0    0    0    0    1    0    0    0    0    0    0    1]\n",
      " [   0  398    8    0    0    0    0    0    0    0    0    0    0    1\n",
      "     0    0    0    1    1    0    0    0    0    6    0    2]\n",
      " [  47    2 9657    1   20    4    2   25   42   13   28    1   13    0\n",
      "    15    6    5    0   19    0   22   38    0    0   12    2]\n",
      " [   0    0   10  377    0    0    0    0    0    0    0    0    0    2\n",
      "     0    0    0    1   16    0    0    0    0    0    0    0]\n",
      " [   0    0  123    0  255    0    0    0    0    0   33    0    0    0\n",
      "     0    2    0    0    0    0    3    0    0    0    0    0]\n",
      " [   0    0    9    6    0  381    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1   29   15    0   21  112    0    0   30    0    0   50   22\n",
      "     0    3   32   14   45    0    0    1    0    4    0   29]\n",
      " [  15    0   44    0    0    0    0  390    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   79    0    2    0    0    0  298    0    8    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   52    1    9    0    3    0    1  356    0    0    0    0\n",
      "     0    1    0    0    0    0    0    0    0    1    0    0]\n",
      " [   0    0  151    0    0    0    0    0    2    0  268    0    0    0\n",
      "     0    0    0    0    0    0    8    0    0    0    0    0]\n",
      " [   0    0    8    0    0    0    0    0    0    0    0  403    0    0\n",
      "     0    0    2    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0  104    0    1    0    3    0    2   62    2    0  129   15\n",
      "     0    7   22    0    0    0    1   42    0    0    0    0]\n",
      " [   0    0   40   37    0   50    0    0    1   27    0    0   45   30\n",
      "     0    3   46    1   82    0    0    0    0    0    0   39]\n",
      " [   4    0  358    0    1    0    0    0    0    1    0    0    3    0\n",
      "    56    0    0    0    0    0    1    0    0    0    0    0]\n",
      " [   0    0   49    0    2    0    0    0    0    1    1    0    2    0\n",
      "     0  320    1    0    0    0    0    3    0    0    0    0]\n",
      " [   0    0   19    0    2    0    0    0    0    0    0    0    0    0\n",
      "     0    1  382    0    1    0    0    0    0    1    0    0]\n",
      " [   0    0    7    0    0   50   21    0    0    0    0    0    0    0\n",
      "     0    0    0  269   38    0    0    0    0    0    0    2]\n",
      " [   0    0   17    0    4   38    0    0    0    0    0    1    0    1\n",
      "     0    1   73    5  209    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    2    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0  371    0    0    0    0    0    0]\n",
      " [   0    0   37    0    0    0    0    0    0    1    0    0    2    0\n",
      "     0    0    0    0    0    0  348    0    0    0    0    0]\n",
      " [   0    0  205    0    1    0    0    0    1    7    3    0  108    0\n",
      "     0    4    0    0    0    0    0   71    0    0    0    0]\n",
      " [   0    0    4    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0  400    0    0    0]\n",
      " [   0    6    0    1    0    0    1    0    0    0    0    0    0    1\n",
      "     0    0    0    0    0    0    0    0    0  356    0    0]\n",
      " [   0    0  364    0    2    0    0    1    1    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0   39    0]\n",
      " [   0    0   47   24    0   41    0    0    3   30    0    0   55   31\n",
      "     0    1   34    3   56    0    0    2    0    0    0   81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gozi       0.78      0.59      0.68       400\n",
      "     corebot       0.98      0.95      0.97       417\n",
      "       alexa       0.83      0.97      0.90      9974\n",
      "     ranbyus       0.82      0.93      0.87       406\n",
      "       symmi       0.85      0.61      0.71       416\n",
      "      emotet       0.65      0.96      0.78       396\n",
      "    dircrypt       0.79      0.27      0.41       408\n",
      "      matsnu       0.93      0.87      0.90       449\n",
      "       simda       0.85      0.77      0.81       387\n",
      "      fobber       0.67      0.84      0.75       424\n",
      "      pushdo       0.78      0.62      0.69       429\n",
      "      qadars       1.00      0.98      0.99       413\n",
      "      kraken       0.32      0.33      0.32       390\n",
      "      ramnit       0.29      0.07      0.12       401\n",
      "      nymaim       0.79      0.13      0.23       424\n",
      "      pykspa       0.92      0.84      0.88       379\n",
      "       tinba       0.64      0.94      0.76       406\n",
      "     murofet       0.91      0.70      0.79       387\n",
      "cryptolocker       0.45      0.60      0.51       349\n",
      "       ramdo       1.00      0.99      1.00       373\n",
      "     vawtrak       0.91      0.90      0.90       388\n",
      "   conficker       0.45      0.18      0.25       400\n",
      "    padcrypt       1.00      0.99      1.00       404\n",
      "      rovnix       0.97      0.98      0.97       365\n",
      "    suppobox       0.76      0.10      0.17       407\n",
      "      necurs       0.52      0.20      0.29       408\n",
      "\n",
      "    accuracy                           0.81     20000\n",
      "   macro avg       0.76      0.67      0.68     20000\n",
      "weighted avg       0.80      0.81      0.78     20000\n",
      "\n",
      "Training for fold:  2\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 278s 441ms/step - loss: 1.4786 - accuracy: 0.6041\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 305s 487ms/step - loss: 0.9508 - accuracy: 0.7143\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 262s 419ms/step - loss: 0.7963 - accuracy: 0.7536\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 238s 381ms/step - loss: 0.7031 - accuracy: 0.7790\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 218s 349ms/step - loss: 0.6432 - accuracy: 0.7950\n",
      "625/625 [==============================] - 22s 33ms/step - loss: 0.5644 - accuracy: 0.8153\n",
      "Score for fold 2: loss of 0.5643842816352844; accuracy of 81.52999877929688%\n",
      "[[ 236    1  190    0    4    0    0    1    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    2    0]\n",
      " [   0  360    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    3    4    0    0    0    0   18    0    0]\n",
      " [  45    4 9508    1   24    6   10   44   20   16   31    8    5    2\n",
      "    25    8    8    0   18    0   13   41    0    4    4    0]\n",
      " [   1    0    5  356    0    2    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0   13    1    0    0    0    0    0    0]\n",
      " [   0    0  127    0  245    0    0    0    0    0   22    0    0    0\n",
      "     0    2    1    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    4    0    2  421    0    0    0    0    0    0    0    0\n",
      "     0    1    0    6    0    5    0    0    0    0    0    0]\n",
      " [   1    0   15   12    1   16  112    0    1   49    0    0   36   19\n",
      "     0    4   22   19   42    1    0    6    0    3    0   21]\n",
      " [  11    0   38    0    0    0    0  359    0    0    0    0    0    0\n",
      "     0    0    0    2    0    0    0    0    0    0    0    0]\n",
      " [   0    0   69    0    3    0    0    0  312    0   12    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   44    3    2    0    0    0    0  361    0    0    0    0\n",
      "     0    3    0    0    0    0    1    0    0    0    0    0]\n",
      " [   0    0  124    0    0    0    0    0    1    0  284    0    0    0\n",
      "     0    0    0    0    0    0    3    0    0    0    0    0]\n",
      " [   0    0    4    0    2    0    0    0    0    0    0  381    0    0\n",
      "     0    3    1    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   87    0    3    0    8    0    5   96    2    0   78    0\n",
      "     0    8   16    0    0    0    0   96    0    0    0    6]\n",
      " [   1    0   43   35    1   24    4    0    0   41    2    0   37   50\n",
      "     0    6   42   14   94    0    0    9    0    1    0   19]\n",
      " [   1    0  275    0    0    0    0    1    0    1    0    0    2    0\n",
      "    90    1    0    0    0    0    1    1    0    0    1    0]\n",
      " [   0    0   68    0    2    0    0    0    0    2    1    0    0    0\n",
      "     0  316    1    0    0    0    0    5    0    0    0    0]\n",
      " [   0    0   15    0    1    0    0    0    0    0    0    2    0    0\n",
      "     0    1  413    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    1    0    0   21   20    0    0    1    0    0    0    0\n",
      "     0    0    1  322   24    0    0    0    0    0    0    5]\n",
      " [   0    0   10    0    2    3    0    0    0    0    0    0    0    0\n",
      "     0    5   84   35  251    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0  423    0    0    0    0    0    0]\n",
      " [   0    0   42    0    0    0    0    0    1    0    2    0    0    0\n",
      "     0    0    1    0    0    0  363    1    0    0    0    0]\n",
      " [   0    0  202    0    3    0    0    0    2    6    0    0   77    0\n",
      "     0    8    0    0    0    0    0  106    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0  459    0    0    0]\n",
      " [   0    0    2    1    0    0    9    0    0    0    0    0    0    1\n",
      "     0    0    0    0    0    0    0    0    0  398    0    0]\n",
      " [   0    0  354    0    0    0    0    0    0    0    2    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0   32    0]\n",
      " [   0    0   29   29    0   37    1    0    0   27    2    0   35   41\n",
      "     0    8   24   18   65    0    0   23    0    0    0   70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gozi       0.80      0.54      0.65       434\n",
      "     corebot       0.99      0.93      0.96       386\n",
      "       alexa       0.84      0.97      0.90      9845\n",
      "     ranbyus       0.81      0.94      0.87       378\n",
      "       symmi       0.83      0.62      0.71       397\n",
      "      emotet       0.79      0.96      0.87       439\n",
      "    dircrypt       0.68      0.29      0.41       380\n",
      "      matsnu       0.89      0.88      0.88       410\n",
      "       simda       0.91      0.79      0.85       396\n",
      "      fobber       0.60      0.87      0.71       414\n",
      "      pushdo       0.79      0.69      0.74       412\n",
      "      qadars       0.97      0.97      0.97       391\n",
      "      kraken       0.29      0.19      0.23       405\n",
      "      ramnit       0.44      0.12      0.19       423\n",
      "      nymaim       0.78      0.24      0.37       374\n",
      "      pykspa       0.84      0.80      0.82       395\n",
      "       tinba       0.67      0.96      0.79       432\n",
      "     murofet       0.77      0.82      0.79       395\n",
      "cryptolocker       0.49      0.64      0.56       390\n",
      "       ramdo       0.98      1.00      0.99       423\n",
      "     vawtrak       0.95      0.89      0.92       410\n",
      "   conficker       0.37      0.26      0.31       404\n",
      "    padcrypt       1.00      1.00      1.00       459\n",
      "      rovnix       0.94      0.97      0.95       411\n",
      "    suppobox       0.82      0.08      0.15       388\n",
      "      necurs       0.58      0.17      0.26       409\n",
      "\n",
      "    accuracy                           0.82     20000\n",
      "   macro avg       0.76      0.68      0.69     20000\n",
      "weighted avg       0.80      0.82      0.79     20000\n",
      "\n",
      "Training for fold:  3\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 313s 495ms/step - loss: 1.4632 - accuracy: 0.6077\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 303s 484ms/step - loss: 0.9385 - accuracy: 0.7164\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 249s 399ms/step - loss: 0.7915 - accuracy: 0.7559\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 278s 444ms/step - loss: 0.7071 - accuracy: 0.7789\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 234s 375ms/step - loss: 0.6503 - accuracy: 0.7936\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 0.5859 - accuracy: 0.8090\n",
      "Score for fold 3: loss of 0.5859114527702332; accuracy of 80.89500069618225%\n",
      "[[ 232    0  152    0    6    0    0    4    0    0    0    0    0    0\n",
      "     2    0    1    0    1    0    0    0    0    0    4    0]\n",
      " [   0  395    5    0    0    0    1    0    0    0    0    0    0    0\n",
      "     0    0    0    2    5    0    0    0    0   26    0    0]\n",
      " [  40    1 9591    4   48    4    5   43   21   17   23    0    9    0\n",
      "    66    7    8    0   10    2   17   13    0    1   26    0]\n",
      " [   0    0    7  318    0   59    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0   16    1    0    0    0    0    0    0]\n",
      " [   1    0   87    0  300    0    0    0    0    0   16    0    0    0\n",
      "     0    2    0    0    0    0    3    0    0    0    0    0]\n",
      " [   0    0    8    0    0  390    0    0    0    0    0    0    0    0\n",
      "     0    3    0   15    6    1    0    0    1    0    0    0]\n",
      " [   0    0   31   21    1   23  134    0    0   44    0    0   40    1\n",
      "     0    5   24   14   52    0    0    0    0    1    0   17]\n",
      " [   8    0   38    0    0    0    0  361    0    0    0    0    0    0\n",
      "     2    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0  105    0    2    0    0    0  259    0   15    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   50    1    2    0    3    0    0  278    0    0   37    0\n",
      "     0    4    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0  147    0    4    0    0    0    5    0  229    0    0    0\n",
      "     0    1    0    0    0    0   13    0    0    0    0    0]\n",
      " [   0    0   11    0    0    0    0    0    0    0    0  402    0    0\n",
      "     0    1    2    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0  107    0    1    0    5    0    4   99    2    0   96    0\n",
      "     0   13    4    0    0    0    0   34    0    0    0    3]\n",
      " [   0    0   43   57    1   36    4    0    0   45    0    1   48    8\n",
      "     0    5   24    1  101    0    0    1    0    0    0   39]\n",
      " [   3    0  249    0    0    0    0    1    0    1    0    0    1    0\n",
      "   141    0    0    0    0    0    0    0    0    0    1    0]\n",
      " [   0    0   54    0    0    0    0    0    0    3    2    0    2    0\n",
      "     0  326    1    0    0    0    1    4    0    0    0    0]\n",
      " [   0    0   16    0    1    0    0    0    0    0    0    0    0    0\n",
      "     0    3  376    0    1    0    0    0    0    0    0    0]\n",
      " [   0    0    3    0    0   27   24    0    0    0    0    0    0    0\n",
      "     0    0    3  298   35    0    0    0    0    0    0    6]\n",
      " [   0    0   28    0    2    0    0    0    0    0    0    0    0    0\n",
      "     0    1  108    3  267    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0  403    0    0    0    0    0    0]\n",
      " [   0    0   38    0    0    0    0    0    0    0    0    0    1    0\n",
      "     0    1    0    0    0    0  347    0    0    0    0    0]\n",
      " [   0    0  210    0    0    0    0    0    6    1    1    0   70    0\n",
      "     0   12    0    0    0    0    0   69    0    0    0    2]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0  416    0    0    0]\n",
      " [   0    1    0    5    0    0    5    0    0    0    0    0    0    2\n",
      "     0    0    0    0    0    0    0    0    0  404    0    1]\n",
      " [   0    0  335    0    0    0    0    0    0    0    1    0    0    0\n",
      "     4    0    0    0    0    0    0    0    0    0   60    0]\n",
      " [   0    0   54   33    0   34    4    0    0   37    1    0   54    3\n",
      "     0    5   30    3   69    0    1   10    0    0    0   79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gozi       0.82      0.58      0.68       402\n",
      "     corebot       0.99      0.91      0.95       434\n",
      "       alexa       0.84      0.96      0.90      9956\n",
      "     ranbyus       0.72      0.79      0.76       401\n",
      "       symmi       0.82      0.73      0.77       409\n",
      "      emotet       0.68      0.92      0.78       424\n",
      "    dircrypt       0.72      0.33      0.45       408\n",
      "      matsnu       0.88      0.88      0.88       409\n",
      "       simda       0.88      0.68      0.77       381\n",
      "      fobber       0.53      0.74      0.62       375\n",
      "      pushdo       0.79      0.57      0.66       399\n",
      "      qadars       1.00      0.97      0.98       416\n",
      "      kraken       0.27      0.26      0.26       368\n",
      "      ramnit       0.57      0.02      0.04       414\n",
      "      nymaim       0.66      0.36      0.46       397\n",
      "      pykspa       0.84      0.83      0.83       393\n",
      "       tinba       0.65      0.95      0.77       397\n",
      "     murofet       0.89      0.75      0.81       396\n",
      "cryptolocker       0.47      0.65      0.55       409\n",
      "       ramdo       0.99      1.00      1.00       403\n",
      "     vawtrak       0.91      0.90      0.90       387\n",
      "   conficker       0.53      0.19      0.27       371\n",
      "    padcrypt       1.00      1.00      1.00       416\n",
      "      rovnix       0.94      0.97      0.95       418\n",
      "    suppobox       0.66      0.15      0.24       400\n",
      "      necurs       0.54      0.19      0.28       417\n",
      "\n",
      "    accuracy                           0.81     20000\n",
      "   macro avg       0.75      0.66      0.68     20000\n",
      "weighted avg       0.80      0.81      0.78     20000\n",
      "\n",
      "Training for fold:  4\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 300s 474ms/step - loss: 1.4800 - accuracy: 0.6049\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 310s 496ms/step - loss: 0.9501 - accuracy: 0.7127\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 290s 464ms/step - loss: 0.8010 - accuracy: 0.7531\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 269s 430ms/step - loss: 0.7104 - accuracy: 0.7762\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 320s 512ms/step - loss: 0.6503 - accuracy: 0.7945\n",
      "625/625 [==============================] - 28s 43ms/step - loss: 0.5597 - accuracy: 0.8186\n",
      "Score for fold 4: loss of 0.5597413778305054; accuracy of 81.85999989509583%\n",
      "[[ 294    0  106    0    6    0    0   11    0    0    0    0    0    0\n",
      "     0    0    0    1    1    0    0    0    0    0    0    2]\n",
      " [   0  368    4    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    1    0    0    0    0   34    0    1]\n",
      " [  93    4 9611   10   37    8    6   69   38   21   43    2    7    1\n",
      "    17   12    2    1    7    0   28   45    2    0    7    0]\n",
      " [   0    0    1  380    1    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0   18    1    0    0    0    0    0    0]\n",
      " [   5    0   98    0  251    0    0    0    0    0   16    0    0    0\n",
      "     0    3    0    0    0    0    1    0    0    0    0    0]\n",
      " [   1    0    6    0    0  401    0    0    0    0    0    0    0    0\n",
      "     0    0    0    1    0    0    0    0    0    0    0    0]\n",
      " [   0    0   32   15    1   11   95    0    0   36    0    0   39   21\n",
      "     0    3   22   21   56    0    0    5    0    0    0   35]\n",
      " [   6    0   19    0    0    0    0  378    0    0    0    0    0    0\n",
      "     2    0    0    1    0    0    0    0    0    0    0    0]\n",
      " [   0    0   58    0    1    0    0    0  313    0   14    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   39    1    4    0    2    0    0  349    0    0    0    0\n",
      "     0    6    0    0    0    0    1    0    0    0    0    0]\n",
      " [   0    0   61    0    0    0    0    0    3    0  305    0    0    0\n",
      "     0    0    0    0    0    0    4    0    0    0    0    0]\n",
      " [   0    0   10    0    0    0    1    0    0    1    0  384    0    0\n",
      "     0    2    1    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   91    0    1    0    6    0    6  103    3    0   88   10\n",
      "     0   16    0    0    0    0    0   55    0    0    0    2]\n",
      " [   0    0   35   36    1   30    0    0    0   37    1    0   38   43\n",
      "     0    7   41    1   88    0    1    1    0    0    0   42]\n",
      " [  14    0  338    0    1    0    0    0    0    0    0    0    2    0\n",
      "    39    0    0    0    1    0    0    0    0    0    0    0]\n",
      " [   0    0   52    0    1    0    0    0    1    2    0    0    0    0\n",
      "     0  351    1    0    0    0    1   16    0    0    0    0]\n",
      " [   0    0   18    0    2    0    0    0    0    0    0    0    0    0\n",
      "     0    1  392    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    4    0    0   38   11    0    0    0    0    0    0    0\n",
      "     0    0    2  284   36    0    0    0    0    0    0    2]\n",
      " [   0    0   24    0    2    0    0    0    0    0    0    0    0    0\n",
      "     0    5   88    4  263    1    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0  415    0    0    0    0    0    0]\n",
      " [   0    0   20    0    0    0    0    0    0    1    0    0    1    0\n",
      "     0    0    0    0    0    0  372    0    0    0    0    0]\n",
      " [   0    0  184    0    1    0    0    0    3    8    3    0   81    1\n",
      "     0   12    0    0    0    0    0   87    0    0    0    2]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0  398    0    0    0]\n",
      " [   0    4    1    1    0    0    5    0    0    0    0    0    0    5\n",
      "     0    0    0    0    0    0    0    0    0  417    0    1]\n",
      " [   1    0  354    0    0    0    0    2    2    1    0    0    0    0\n",
      "     0    0    0    0    0    0    3    0    0    0   32    0]\n",
      " [   0    0   36   20    3   22    1    0    1   29    0    0   36   30\n",
      "     0    3   33   11   64    0    0    9    0    0    0   62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gozi       0.71      0.70      0.70       421\n",
      "     corebot       0.98      0.90      0.94       408\n",
      "       alexa       0.86      0.95      0.90     10071\n",
      "     ranbyus       0.82      0.95      0.88       401\n",
      "       symmi       0.80      0.67      0.73       374\n",
      "      emotet       0.79      0.98      0.87       409\n",
      "    dircrypt       0.75      0.24      0.37       392\n",
      "      matsnu       0.82      0.93      0.87       406\n",
      "       simda       0.85      0.81      0.83       386\n",
      "      fobber       0.59      0.87      0.71       402\n",
      "      pushdo       0.79      0.82      0.80       373\n",
      "      qadars       0.99      0.96      0.98       399\n",
      "      kraken       0.30      0.23      0.26       381\n",
      "      ramnit       0.39      0.11      0.17       402\n",
      "      nymaim       0.67      0.10      0.17       395\n",
      "      pykspa       0.83      0.83      0.83       425\n",
      "       tinba       0.67      0.95      0.79       413\n",
      "     murofet       0.87      0.75      0.81       377\n",
      "cryptolocker       0.49      0.68      0.57       387\n",
      "       ramdo       1.00      1.00      1.00       415\n",
      "     vawtrak       0.91      0.94      0.92       394\n",
      "   conficker       0.40      0.23      0.29       382\n",
      "    padcrypt       0.99      1.00      1.00       398\n",
      "      rovnix       0.92      0.96      0.94       434\n",
      "    suppobox       0.82      0.08      0.15       395\n",
      "      necurs       0.42      0.17      0.24       360\n",
      "\n",
      "    accuracy                           0.82     20000\n",
      "   macro avg       0.75      0.69      0.68     20000\n",
      "weighted avg       0.80      0.82      0.79     20000\n",
      "\n",
      "Training for fold:  5\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 262s 415ms/step - loss: 1.4900 - accuracy: 0.6016\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 205s 327ms/step - loss: 0.9639 - accuracy: 0.7106\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 209s 335ms/step - loss: 0.8109 - accuracy: 0.7514\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 206s 329ms/step - loss: 0.7099 - accuracy: 0.7789\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 205s 327ms/step - loss: 0.6486 - accuracy: 0.7942\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 0.5591 - accuracy: 0.8186\n",
      "Score for fold 5: loss of 0.5590904355049133; accuracy of 81.85999989509583%\n",
      "[[ 254    0  103    0    6    0    0    3    0    0    0    0    0    0\n",
      "     1    0    0    0    1    1    1    0    0    0    0    0]\n",
      " [   0  344    4    0    0    0    1    0    0    0    0    0    0    0\n",
      "     0    0    0    2    4    0    0    0    0   28    0    1]\n",
      " [ 111    3 9681    4   27    4    2   47   40    9   86    0   22    3\n",
      "    44    7    3    0   13    1   30   16    0    1    1    0]\n",
      " [   1    0    9  351    3    7    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0   12    1    0    0    0    0    0    0]\n",
      " [   5    0  104    0  247    0    0    0    1    0   35    0    0    0\n",
      "     0    4    0    0    0    0    1    0    0    0    0    0]\n",
      " [   0    0    5    0    1  375    0    0    0    0    0    0    0    0\n",
      "     0    0    0    3    0    2    0    0    1    0    0    0]\n",
      " [   0    1   27   21    2   13  118    0    0   18    3    0   58   24\n",
      "     0    3   17    8   44    0    0    1    0    1    0   30]\n",
      " [   7    0   25    0    0    0    0  330    0    0    0    0    0    0\n",
      "     1    0    0    2    0    0    0    0    0    0    0    0]\n",
      " [   0    0   69    0    1    0    0    0  337    0   10    0    0    0\n",
      "     0    1    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   30    1    1    0    2    0    1  339    0    0    0    0\n",
      "     0    3    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   56    0    0    0    0    0    1    0  338    0    0    0\n",
      "     0    0    0    0    0    0    1    0    0    0    0    0]\n",
      " [   0    0   10    0    0    0    0    0    0    0    0  376    0    0\n",
      "     0    3    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   94    0    1    0    5    0    1   79    4    0  148   16\n",
      "     0    8    3    0    0    0    1   34    0    0    0    0]\n",
      " [   0    0   27   42    1   27    1    0    0   19    3    0   56   46\n",
      "     0    5   32    4   95    0    1    2    0    0    0   20]\n",
      " [   8    0  267    0    0    1    0    0    0    1    0    0    3    0\n",
      "   134    1    0    0    0    0    0    2    0    0    0    0]\n",
      " [   0    0   45    0    0    0    0    0    1    0    5    0    5    0\n",
      "     0  326    0    0    0    0    0   10    0    0    0    0]\n",
      " [   0    0   23    0    0    0    0    0    0    0    0    1    0    0\n",
      "     0    1  360    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    6    0    0   22   27    0    0    0    0    0    0    1\n",
      "     0    0    1  289   34    0    0    0    0    0    0    8]\n",
      " [   0    0   21    0    5    0    0    0    0    0    0    0    0    1\n",
      "     0    6  100    4  274    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0  399    0    0    0    0    0    0]\n",
      " [   0    0   37    0    0    0    0    0    0    0    2    0    1    0\n",
      "     0    0    0    0    0    0  387    0    0    0    0    0]\n",
      " [   0    0  240    0    0    0    0    0    2    0    1    0  103    2\n",
      "     0   16    0    0    0    0    0   69    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0  391    0    0    0]\n",
      " [   0    2    0    2    0    0    2    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0  373    0    0]\n",
      " [   2    0  375    0    0    0    0    0    1    0    2    0    0    0\n",
      "     0    0    0    0    0    0    3    0    0    0   12    0]\n",
      " [   0    0   43   35    2   25    1    0    0   26    1    0   47   26\n",
      "     0    8   23    2   75    1    0    8    0    0    0   74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gozi       0.65      0.69      0.67       370\n",
      "     corebot       0.98      0.90      0.94       384\n",
      "       alexa       0.86      0.95      0.90     10155\n",
      "     ranbyus       0.77      0.91      0.84       384\n",
      "       symmi       0.83      0.62      0.71       397\n",
      "      emotet       0.79      0.97      0.87       387\n",
      "    dircrypt       0.74      0.30      0.43       389\n",
      "      matsnu       0.87      0.90      0.89       365\n",
      "       simda       0.88      0.81      0.84       418\n",
      "      fobber       0.69      0.90      0.78       377\n",
      "      pushdo       0.69      0.85      0.76       396\n",
      "      qadars       1.00      0.97      0.98       389\n",
      "      kraken       0.33      0.38      0.35       394\n",
      "      ramnit       0.39      0.12      0.18       381\n",
      "      nymaim       0.74      0.32      0.45       417\n",
      "      pykspa       0.83      0.83      0.83       392\n",
      "       tinba       0.67      0.94      0.78       385\n",
      "     murofet       0.92      0.74      0.82       388\n",
      "cryptolocker       0.50      0.67      0.57       411\n",
      "       ramdo       0.99      1.00      0.99       399\n",
      "     vawtrak       0.91      0.91      0.91       427\n",
      "   conficker       0.49      0.16      0.24       433\n",
      "    padcrypt       1.00      1.00      1.00       391\n",
      "      rovnix       0.93      0.98      0.95       379\n",
      "    suppobox       0.92      0.03      0.06       395\n",
      "      necurs       0.56      0.19      0.28       397\n",
      "\n",
      "    accuracy                           0.82     20000\n",
      "   macro avg       0.77      0.69      0.69     20000\n",
      "weighted avg       0.81      0.82      0.79     20000\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.5805745720863342 - Accuracy: 80.97000122070312%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 81.42300009727478 (+- 0.4188980100871774)\n",
      "> Loss: 0.5699404239654541\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.5643842816352844 - Accuracy: 81.52999877929688%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 81.42300009727478 (+- 0.4188980100871774)\n",
      "> Loss: 0.5699404239654541\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.5859114527702332 - Accuracy: 80.89500069618225%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 81.42300009727478 (+- 0.4188980100871774)\n",
      "> Loss: 0.5699404239654541\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.5597413778305054 - Accuracy: 81.85999989509583%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 81.42300009727478 (+- 0.4188980100871774)\n",
      "> Loss: 0.5699404239654541\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.5590904355049133 - Accuracy: 81.85999989509583%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 81.42300009727478 (+- 0.4188980100871774)\n",
      "> Loss: 0.5699404239654541\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ο παραπάνω κώδικας επιλύει το πρόβλημα της ταξινόμησης ονομάτων DNS ως προς το αν αυτά τα ονόματα είναι καλόβουλα ή έχουν παραχθεί από Domain Generation Algorithms (DGA's). Συγκεκριμένα, ο κώδικας επιλύει ένα πρόβλημα multi-class classification, όπου τα ονόματα αντιστοιχίζονται είτε στην κατηγορία alexa, εάν είναι καλόβουλα ή στην αντίστοιχα κατηγορία malware στην οποία ανήκουν. Το μοντέλο που έχει χρησιμοποιηθεί για την ταξινόμηση των ονομάτων είναι το LSTM, ενώ για το κατάλληλο validation του μοντέλου έχει χρησιμοποιηθεί η μέθοδος K-fold cross validation με Κ = 5. Τα δεδομένα εκπαίδευσης και αξιολόγησης έχουν ληφθεί από <a href=\"https://github.com/chrmor/DGA_domains_dataset\">εδώ</a> και χρησιμοποιούνται τα πρώτα 100000 ονόματα του αρχείου \"dga_domains_full.csv\". \n",
    "\n",
    "Μελετώντας τον κώδικα και εκτελώντας τον, να απαντήσετε στις ακόλουθες ερωτήσεις:\n",
    "<ul>\n",
    "<li>Γιατί το LSTM είναι κατάλληλο μοντέλο για την επίλυση του συγκεκριμένου προβλήματος;</li>\n",
    "<li>Τι είναι η λίστα ονομάτων Alexa (<a href=\"https://en.wikipedia.org/wiki/Alexa_Internet\">info</a>), ονόματα της οποίας έχουν χρησιμοποιηθεί για την κατηγορία των καλόβουλων ονομάτων;</li>\n",
    "<li>Να διαλέξετε δύο οικογένειες malware από την κατηγορία dga, δηλαδή την κατηγορία με τα κακόβουλα ονόματα που αντιστοιχούν σε malware. Να αναζητήσετε τι προβλήματα δημιουργούν τα malware αυτά, π.χ. υποκλοπή τραπεζικών κωδικών, έναρξη επιθέσεων DDoS, κλπ.</li>\n",
    "<li>Να περιγράψετε σύντομα τα βήματα που ακολουθεί το παραπάνω πρόγραμμα για την επίλυση του προβλήματος.</li>\n",
    "<li>Ποιος είναι ο ρόλος του embedding layer και τι παραμέτρους δέχεται;</li>\n",
    "<li>Να αναφέρετε λόγους για τους οποίους χρησιμοποιείται η μέθοδος K-fold cross validation.</li>\n",
    "<li>Κατά τη χρήση της μεθόδου K-fold cross validation, ανά fold, να αναφέρετε πόσα examples χρησιμοποιούνται για την εκπαίδευση του μοντέλου και πόσα για το validation/testing.\n",
    "<li>Δείτε <a href=\"https://en.wikipedia.org/wiki/Cross-validation_(statistics)\">εδώ</a> μεθόδους που μπορεί να χρησιμοποιούν έναντι της μεθόδου K-fold cross validation. Να αναφέρετε μερικά πλεονεκτήματα και μειονεκτήματά τους.</li>\n",
    "<li>Να αναλύσετε τα κριτήρια precision, recall και F1-score που εμφανίζονται στο classification report.</li>\n",
    "<li>Σε ποιες κατηγορίες πετυχαίνουμε καλύτερα αποτελέσματα και σε ποιες χειρότερα; Γιατί πιστεύετε ότι παίρνουμε αυτά τα αποτελέσματα;</li>\n",
    "</ul>"
   ],
   "metadata": {
    "id": "MZNG1h91eQwn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<li><i>Γιατί το LSTM είναι κατάλληλο μοντέλο για την επίλυση του συγκεκριμένου προβλήματος;</i></li>\n",
    "\n",
    "Το LSTM διατηρεί ένα cell state το οποίο δίνει στο μοντέλο τη δυνατότητα να αποθηκεύει πληροφορία από προηγούμενα δεδομένα μιας ακολουθίας δεδομένων. Στο υπό μελέτη πρόβλημα, αξιοποιούνται 100,000 διευθύνσεις (<a href=\"https://github.com/chrmor/DGA_domains_dataset\">data source</a>) από ένα dataset 675,000 domain names (διευθύνσεων), εκ των οποίων οι 50\\% είναι Alexa domains, και τα υπόλοιπα 50\\% έχουν παραχθεί από 25 διαφορετικές οικογένειες Domain Generation Algorithms (DGAs). Κάθε οικογένεια εκ των 25 έχει συνεισφέρει από 13,500 domains, ενώ από τους 25 DGA algortihms, οι 13 είναι time dependent και οι εναπομείναντες 12 time independent. Από το dataset αυτό χρησιμοποιούνται μόνο οι 100,000 πρώτες εγγραφές που περιέχουν περίπου 50,000 dga generated domain names και 50,000 legit domain names όπως αυτά έχουν παρθεί από το Alexa (legit domains).\n",
    "\n",
    "Εφόσον κάθε domain name string μπορεί να θεωρηθεί ως μια ακολουθία χαρακτήρων (chars), τότε το LSTM μπορεί να διατηρεί μνήμη για την ακολουθία πριν κάνει την τελική πρόβλεψη. Μέσω του cell state, όπως αναφέρθηκε, μεταφέρεται παρελθοντική πληροφορία από την ακολουθία στο τελευταίο LSTM cell, όπου και γίνεται η τελική πρόβλεψη για την κατηγορία ενός domain name. Αυτή η λειτουργία του LSTM λέγεται seq2vec, όπου δηλαδή μια ακολουθία δεδομένων δίνεται ως είσοδος και στην έξοδο παίρνουμε ένα διάνυσμα, από το οποίο εξάγεται η κλάση στην οποία ταξινομείται ένα domain name (ακολουθία). Tα LSTM μπορούν να ανακαλύψουν, συνεπώς, συσχετίσεις μεταξύ των χαρακτήρων της κάθε ακολουθίας οδηγώντας σε καλύτερη ταξινόμηση τελικά."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<li><i>Τι είναι η λίστα ονομάτων Alexa (<a href=\"https://en.wikipedia.org/wiki/Alexa_Internet\">info</a>), ονόματα της οποίας έχουν χρησιμοποιηθεί για την κατηγορία των καλόβουλων ονομάτων;</i></li>\n",
    "\n",
    "Η Alexa ήταν μια Αμερικάνικη εταιρεία ανάλυσης διαδικτυακής κίνησης (web traffic). Ανήκε εξ ολοκλήρου στην Amazon και η υπηρεσία Alexa σταμάτησε τη λειτουργία της τον Μάιο του 2022. Παρείχε δεδομένα διαδικτυακής κίνησης, παγκόσμιες κατατάξεις και άλλες πληροφορίες για πάνω από 30 εκατομμύρια ιστότοπους. Στο υποσόνολο των 100,000 domain names που χρησιμοποιείται, περί τα 50,000 είναι καλόβουλα, υπαρκτά domain names (legit) και έχουν προέλθει από τη λίστα αυτών των 30 εκατομμυρίων websites που έκανε track η Alexa.\n",
    "\n",
    "Αντίθετα, τα υπόλοιπα περίπου 50,000 domain names είναι μη υπαρκτά dga generated domain names."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<li><i>Να διαλέξετε δύο οικογένειες malware από την κατηγορία dga, δηλαδή την κατηγορία με τα κακόβουλα ονόματα που αντιστοιχούν σε malware. Να αναζητήσετε τι προβλήματα δημιουργούν τα malware αυτά, π.χ. υποκλοπή τραπεζικών κωδικών, έναρξη επιθέσεων DDoS, κλπ.</i></li>\n",
    "\n",
    "Όπως αναφέραμε προηγουμένως, τα μη υπαρκτά/τεχνητά domain names προέρχονται από 25 οικογένειες DGA αλγορίθμων. Αυτές είναι οι εξής:\n",
    "\n",
    "\\begin{table}\n",
    " \\begin{tabular}{||c ||}\n",
    " \\hline\n",
    " \\text{DGA family} \\\\\n",
    " \\hline\\hline\n",
    " gozi \\\\\n",
    " corebot \\\\\n",
    " ranbyus \\\\\n",
    " symmi \\\\\n",
    " emotet \\\\\n",
    " dircrypt \\\\\n",
    " matsnu \\\\\n",
    " simda \\\\\n",
    " fobber \\\\\n",
    " pushdo \\\\\n",
    " qadars \\\\\n",
    " kraken \\\\\n",
    " ramnit \\\\\n",
    " nymaim \\\\\n",
    " pykspa \\\\\n",
    " tinba \\\\\n",
    " murofet \\\\\n",
    " cryptolocker \\\\\n",
    " ramdo \\\\\n",
    " vawtrak \\\\\n",
    " conficker \\\\\n",
    " padcrypt \\\\\n",
    " rovnix \\\\\n",
    " suppobox \\\\\n",
    " necurs \\\\\n",
    " \\hline\n",
    " \\end{tabular}\n",
    "\\end{table}\n",
    "\n",
    "Ενδεικτικά, θα περιγράψουμε τα προβλήματα που δημιουργούν 2 από αυτές τις οικογένεις malware, την kraken και την ......\n",
    "\n",
    "Η **Kraken** είναι η πρώτη οικογένεια malware που χρησιμοποίησαν DGAs το 2008. Είναι network hacking spyware software που επιτίθεται στα Microsoft Windows και Apple Macintosh λειτουργικά συστήματα μέσω email και world wide web sites όπως μέσα κοινωνικής δικτύωσης. Οι συσκευές που γίνονται infected χρησιμοποιούνται συνήθως για να στέλνουν spam email messages.\n",
    "\n",
    "Ουσιαστικά, όλη η λογική πίσω από την παραγωγή domain names (DGA) από κώδικα που τρέχει σε infected συσκευή, αφορά την αποφυγή να γίνουν blacklisted οι Command & Control Servers που μπορεί να χρησιμοποιούνται. Για παράδειγμα, ο DGA του kraken γεννά μέσω ενός seeded αλγορίθμου ένα πλήρες domain name με ένα τυχαίο string που αποτελείται από σύμφωνα και φωνήεντα που σχεδόν μιμούνται την αγγλική γραμματική και δομή των λέξεων λόγω shifting των χαρακτήρων. Όταν μια τυχαία λέξη λοιπόν παραχθεί τότε γίνεται append ένα domain suffix ώστε να δημιουργηθεί το τελικό domain name. Έπειτα μια IoT συσκευή κατά βάση προσπαθεί να συνδεθεί με τον command & control server για να λάβει το επόμενο σετ οδηγιών.\n",
    "\n",
    "Η **Cryptolocker** malware οικογένεια, από την άλλη, πρόκειται για ένα trojan horse που μολύνει έναν υπολογιστή κι έπειτα αναζητά αρχεία προς κρυπτογράφηση, συμπεριλαμβανομένου αρχείων στον σληρό δίσκο και άλλα μέσα αποθήκευσης (πχ USB memory sticks). Επίσης, μπορεί να αναζητά αρχεία και φακέλους αποθηκευμένους στο cloud. Κάνουν infect μόνο στο Windows λειτουργικό και όχι Macintosh. Το malware όταν μολυνθεί ένας υπολογιστής εφαρμόζειμια μέθοδο encryption στα αρχεία που λέγεται assymetric και βασίζεται σε ένα δημόσιο και ένα ιδιωτικό κλειδί. Οι hackers κωδικοποιούν τα δεδομένα χρησιμοποιώντας το δημόσιο κλειδί, ωστόσο για την αποκρυπτογράφηση χρειάζεται και το μοναδικό ιδιωτικό κλειδί που κατέχουν. Το malware αυτό όταν κρυπτογραφήσει τα δεδομένα εμφανίζει παράθυρα που ενημερώνουν το χρήστη ότι τα δεδομένα θα καταστραφούν αν δεν πληρωθεί κάποιο χρηματικό ποσό για να λάβει το ιδιωτικό κλειδί αποκρυπτογράφησης."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<li><i>Να περιγράψετε σύντομα τα βήματα που ακολουθεί το παραπάνω πρόγραμμα για την επίλυση του προβλήματος.<i></li>\n",
    "\n",
    "Αρχικά, διαβάζεται το πλήρες dataset και επιστρέφεται μια λίστα που περιέχει ζεύγη τιμών σε λίστες [domain_name_prefix, family], όπου το domain_name_prefix είναι το string που προηγείται της τελείας στο domain name και family μπορεί να παίρνει οποιαδήποτε από 26 τιμές (25 για τις οικογένειες DGA και άλλη μία η 'alexa'). Επίσης επιστρέφονται οι μοναδικοί χαρακτήρες (chars) που έχουν εμφανιστεί στα prefixes αυτά, ενώ υπολογίζεται και το μέγιστο μήκος prefix όπως και ένα dictionary με keys τις 26 κατηγορίες και values από 0 έως 25 για τις κατηγορίες αυτές.\n",
    "\n",
    "Έπειτα, κρατούνται μόνο οι 100,000 πρώτες εγγραφές του dataset. Ύστερα ως χαρακτηριστικά λογίζονται οι μοναδικοί χαρακτήρες που εμφανίζονται στο dataset και τους γίνεται assigned ως value ένα index  (σε dict με keys τα chars αυτά και values τα indexes). Κατόπιν, το dataset μετατρέπεται/γίνεται tokenized, υπό την έννοια ότι κάθε στοιχείο του dataset μετασχηματίζεται και παίρνει αριθμητικές τιμές συν το label (κατηγορία από τις 26), ενώ προστίθεται και padding όπου χρειάζεται ώστε να έχουν ίδιο μήκος χαρακτηριστικών τα διάφορα στοιχεία του dataset. Ύστερα, χωρίζονται τα examples με τα χαρακτηριστικά και το label, και έπειτα ακολουθεί ένα 5-fold cross validation.\n",
    "\n",
    " Στο cross validation, για κάθε iteration της διαδικασίας, χωρίζεται το dataset σε X_train, y_train, X_test, y_test και δημιουργείται ένα μοντέλο LSTM, το οποίο εκπαιδεύται στα δεδομένα εκπαίδευσης για 5 εποχές με batch size 128 (δηλαδή 128 δειγματικά στοιχεία περνούν στο forward pass τη φορά πριν υπολογιστούν τα gradients και γίνει ένα update στα βάρη του δικτύου). Ύστερα το εκπαιδευμένο μοντέλο χρησιμοποιείται για πρόβλεψη ετικετών/κλάσεων στα δεδομένα του X_test και επιστρέφονται το classification report και το confusion matrix στο test fold."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<li></i>Ποιος είναι ο ρόλος του embedding layer και τι παραμέτρους δέχεται;</i></li>\n",
    "\n",
    "Όπως αναφέρθηκε προηγουμένως, για να λειτουργήσει το δίκτυο LSTM απαιτείται φυσικά να δουλέψει με αριθμητικά διανύσματα. Έτσι, μετασχηματίσαμε τα prefix strings σε διανύσματα/λίστες με τιμές χαρακτηριστικών. Το embedding layers μετατρέπει με τη σειρά του φυσικούς (αριθμούς) σε dense διανύσματα με συγκεκριμένο μήκος/μέγεθος. Ουσιαστικά χρησιμοποιείται πριν εισαχθούν τα δεδομένα στο LSTM. Δέχεται ορισμένες παραμέτρους όπως το μέγιστο μήκος ενός string στα prefixes των domain name strings όπως και το επιθυμητό μήκος των διανυσμάτων εξόδου."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<li><i>Να αναφέρετε λόγους για τους οποίους χρησιμοποιείται η μέθοδος K-fold cross validation.</i></li>\n",
    "\n",
    "Η μέθοδος k-fold cross validation είναι μια μέθοδος resampling που χρησιμοποιεί διαφορετικά κομμάτια των δεδομένων για να εκπαιδεύσει και να αποτιμήσει ένα μοντέλο σε διαφορετικά (k σε αριθμό) iterations. Χρησιμοποιείται κυρίως σε περιπτώσεις όπου πρωταρχικός στόχος είναι η πρόβλεψη και κανείς θέλει να εκτιμήσει την ακρίβεια την οποία το προβλεπτικό μοντέλο αναμένεται να έχει στην πράξη σε νέα δεδομένα. Η μέθοδος μπορεί επίσης να βοηθήσει στον εντοπισμό προβλημάτων όπως το overfitting ή το selection bias.\n",
    "\n",
    "Με τη μέθοδο k-fold cross validation, εκπαιδεύονται ουσιαστικά k ταξινομητές της ίδιας κλάσης σε διαφορετικά k-1 folds κάθε φορά ως σύνολα εκπαίδευσης, και η αποτίμηση γίνεται στο k-οστό fold. Κάνοντας aggregate τις αποτιμήσεις των k αυτών μοντέλων πρακτικά κινούμαστε προς έναν μέσο όρο της απόδοσης της κλάσης αυτής του ταξινομητή στο πρόβλημα που εξετάζεται, απαλείφοντας εξαρτήσεις με μέρος των δεδομένων που θα μπορούσαν να οδηγούν σε τυχαία πολύ καλά ή πολύ άσχημα αποτελέσματα."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<li><i>Κατά τη χρήση της μεθόδου K-fold cross validation, ανά fold, να αναφέρετε πόσα examples χρησιμοποιούνται για την εκπαίδευση του μοντέλου και πόσα για το validation/testing</i>.</li>\n",
    "\n",
    "Αν υποθέσουμε πως τα δειγματικά στοιχεία του συνόλου δεδομένων (δείγμα) είναι $N$ σε αριθμό, τότε για κάθε μια επανάληψη (ανά test fold) του cross validation, έχουμε:\n",
    "- Ο αριθμός των δειγματικών στοιχείων ανά fold είναι $\\frac{N}{k}$ αν υποθέσουμε πως διαιρείται το $Ν$ ακριβώς με το $k$.\n",
    "- $k-1$ folds για εκπαίδευση, ήτοι $(k-1) \\cdot \\frac{N}{k} = \\frac{k-1}{k} \\cdot N$ δειγματικά στοιχεία εκπαίδευσης.\n",
    "- 1 fold για αξιολόγηση, ήτοι $1 \\cdot \\frac{N}{k} = \\frac{1}{k} \\cdot N$ δειγματικά στοιχεία.\n",
    "\n",
    "Όπως είναι εμφανές τα δειγματικά στοιχεία εκπαίδευσης συν τα δειγματικά στοιχεία αξιολόγησης αθροίζουν σε αριθμό στο $Ν$. Εν προκειμένω έχουμε $Ν=100,000$, οπότε για $k=5$ έχουμε $\\frac{k-1}{k} \\cdot N = \\frac{5-1}{5} \\cdot 100,000 = 80,000$ δειγματικά στοιχεία εκπαίδευσης και  $\\frac{1}{k} \\cdot N = \\frac{1}{5} \\cdot 100,000 = 20,000 $ δειγματικά στοιχεία αξιολόγησης για κάθε iteration/fold."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<li><i>Δείτε <a href=\"https://en.wikipedia.org/wiki/Cross-validation_(statistics)\">εδώ</a> μεθόδους που μπορεί να χρησιμοποιούν έναντι της μεθόδου K-fold cross validation. Να αναφέρετε μερικά πλεονεκτήματα και μειονεκτήματά τους.</i></li>\n",
    "\n",
    "Αρχικά, υπάρχουν δύο μέθοδοι cross-validation, οι **exhaustive**, και οι **non-exhaustive**.\n",
    "\n",
    "Οι **exhaustive** μέθοδοι είναι cross-validation μέθοδοι που μαθαίνουν και εξετάζεται η επίδοσή τους με όλους τους πιθανούς τρόπους διαίρεσης/διαχωρισμού του αρχικού δείγματος σε training και validation sets. Εν αντιθέσει, οι **non-exhaustive** μέθοδοι δεν υπολογίζουν ή εξετάζουν όλους του πιθανούς τρόπους διαίρεσης/διαχωρισμού του δείγματος και αποτελούν προσεγγίσεις του leave-p-out cross-validation. Η μέθοδος k-fold cross-validation αποτελεί μια τέτοια μέθοδο (non-exhaustive).\n",
    "\n",
    "Η μέθοδος leave-p-out cross-validation (LpO CV) πόυ αναφέρθηκε είναι exhaustive μέθοδος, και χρησιμοποιεί ένα σύνολο p παρατηρήσεων ως validation set και τις υπόλοιπες παρατηρήσεις ως το training set. Αυτό επαναλαμβάνεται για όλους τους τρόπους που μπορεί να χωριστεί το αρχικό σύνολο δεδομένων/δείγμα σε validation και training set υπό τη συνθήκη το validation set να περιέχει p παρατηρήσεις. Αν το δείγμα έχει μέγεθος n (συνολικός αριθμός παρατηρήσεων), τότε για $p>1$ πολύ εύκολα και όχι για τεράστιο n ο υπολογισμός μπορεί να μην είναι καν υλοποιήσιμος από υπολογιστική σκοπιά. Για παράδειγμα, αν $n=100$ και $p=20$, τότε θα χρειαστούν $C_p^n=C_{20}^{100}=\\binom{100}{20} \\approx 5.4 \\cdot 10^{20}$ μοντέλα να εκπαυδευτούν με το training set και να γίνει αξιολόγηση τους πάνω στο test set ώστε να έχουμε εφαρμόσει την LpO CV μέθοδο. Αυτό είναι και το βασικό μειονέκτημα της μεθόδου και ένας από τους λόγους που χρησιμοποιούμε non-exhaustive μεθόδους όπως το k-fold cross validation. Για $p=1$, η προηγούμενη μέθοδος ανάγεται στην leave-one-out-cross-validation exhaustive μέθοδο, όπου το validation set είναι μια ακριβώς παρατήρηση. Όπως είναι εμφανές στην περίπτωση αυτή έχουμε $C_p^n=C_{1}^{100}=\\binom{100}{1} = 100$ μοντέλα και εν γένει n μοντέλα για μέγεθος δείγματος n. Αν το n είναι σχετικά μικρό η μέθοδος αυτή μπορεί να εφαρμοστεί, ωστόσο για n μεγάλο, τα μειονεκτήματα είναι και πάλι τα ίδια με πριν. Άλλοι μέθοδοι από τις non-exhaustive που μπορούν να χρησιμοποιηθούν αντί της k-fold cross validation είναι η **holdout method** και η **repeated random sub-sampling validation** μέθοδος. Η holdout μέθοδος ουσιαστικά αφορά το διαχωρισμό των δεδομένων σε train και test sets, την εκπαίδευση στο train και την αξιολόγηση στο test set. Η απουσία multiple runs και averaging του κριτηρίου αξιολόγης όπως γίνεται στο k-fold cross validation μπορεί να οδηγήσει σε παραπλανητικά αποτελέσματα με τη χρήση της holdout μεθόδου.  Η repeated random sub-sampling validation μέθοδος (επίσης γνωστή ως Monte-carlo cross-validation) δημιουργεί τυχαία splits του dataset σε training και validation sets. Έτσι κάποιες παρατηρήσεις μπορεί να μην επιλεχθούν ποτέ ως μέρη του validation set ενώ άλλες παρατηρήσεις μπορεί να επιλεγούν παραπάνω από μία φορές. Με τη μέθοδο αυτή απομπλέκονται ο αριθμός επαναλήψεων της εκπαίδευσης και αξιολόγης του μοντέλου (k στην περίπτωση του k-fold cross validation) από τη σχέση αναφορικά με τον αριθμό δειγματικών στοιχείων που περιέχουν μεταξύ train και validation sets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<li><i>Να αναλύσετε τα κριτήρια precision, recall και F1-score που εμφανίζονται στο classification report.</i></li>\n",
    "\n",
    "Tα κριτήρια precision, recall και F1-score είναι μετρικές απόδοσης της ταξινόμησης.\n",
    "\n",
    "<ul>\n",
    "<li> Precision: Το precision εκφράζει τη δυνατότητα ενός ταξινομητή να ανακαλύπτει μόνο τα σχετικά data points. Απαντά στην ερώτηση \"Τι ποσοστό των θετικά ταξινομημένων δειγματικών στοιχείων ήταν τελικά πραγματικά θετικά\" και ορίζεται ως $Precision=\\frac{TP}{TP+FP}$. Σε ένα παράδειγμα με 2 κλάσεις, έστω πρόβλεψη ύπαρξης καρκίνου (έστω ότι η κλάση ασθενή με καρκίνο είναι η θετική και χωρίς καρκίνο είναι η αρνητική), εάν ο ταξινομητής έχει precision ίσο με 0.5, τότε όταν προβλέπει ότι ένας ασθενής έχει καρκίνο τότε έχει 50% πιθανότητα να έχει κάνει σωστή πρόβλεψη. </li>\n",
    "<li> Recall: Το recall εκφράζει τον αριθμό των data points που ένας ταξινομητής σωστά αναγνώρισε ότι ανήκουν στη θετική κλάση από το συνολικό αριθμό θετικών δειγματικών στοιχείων. Απαντά στην ερώτηση \"Τι ποσοστό των πραγματικά θετικών δειγμάτων ταξινομήθηκαν σωστά\" και ορίζεται ως $Recall=\\frac{TP}{TP+FN}$. Στο ίδιο παράδειγμα με τον καρκίνο, αν το μοντέλο μας έχει μετρική αξιολόγησης recall ίση με 0.2 τότε αναγνωρίζει σωστά το 20% των ασθενών με καρκίνο.</li>\n",
    "<li> F1-score: Είναι οαρμονικός μέσος όρος των precision και recall, δηλαδή $F1-score = 2 \\cdot frac{Precision \\cdot Recall}{Precision + Recall}$. Με το F1-score συνδυάζονται πρακτικά και οι δύο μετρικές σε μία.</li>\n",
    "</ul>\n",
    "Αξίζει να σημειώσουμε και το accuracy metric, όπου $Accuracy =  \\frac{TP+TN}{TP+TN+FP+FN}$ ως μετρική αξιολόγησης ενός ταξινομητή. Ωστόσο, ειδικά σε περιπτώσεις που ειναι οι κλάσεις είναι μη ισορροπημένες, η μετρική αυτή είναι προβληματική πιθανότατα καθώς μπορεί να δίνει τη λανθασμένη εντύπωση πως ο ταξινομητής γενικεύει ικανοποιητικά πετυχαίνοντας καλά σκορ στη μετρική αυτή του accuracy, χωρίς αυτό να αντικατοπτρίζει την πραγματικότητα. Σε τέτοιες ειδικά περιπτώσεις επιβάλλεται η χρήση και άλλων μετρικών όπως το precision, recall, f1-score.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<li><i>Σε ποιες κατηγορίες πετυχαίνουμε καλύτερα αποτελέσματα και σε ποιες χειρότερα; Γιατί πιστεύετε ότι παίρνουμε αυτά τα αποτελέσματα;</i></li>\n",
    "\n",
    "Από το classification report στα 5 folds παρατηρούμε ότι η κατηγορία Alexa που αφορά τα πραγματικά domain names και περίπου τα μισά δειγματικά στοιχεία του test set πετυχαίνει καλά classification metrics, ενώ από τις υπόλοιπες 25 κατηγορίες με DGA generated domain names, άλλες πάνε καλύτερα και κάποιες έχουν πολύ χαμηλά scores. Γενικά στα 5 folds τα αποτελέσματα είναι πανομοιότυπα χωρίς σημαντικές αποκλίσεις. Κάποιες κλάσεις που παρατηρούμε ότι επιστρέφουν σχετικά χαμηλές μετρικές αξιολόγησης είναι οι εξής: dircrypt, kraken, ramnit και suppobox. Στην κλάση alexa και στην corebot εν αντιθέσει, η ταξινόμηση επιστρέφει ικανοποιητικά αποτελέσματα.\n",
    "\n",
    "Ένας από τους λόγους της κακής απόδοσης σε κάποιες από τις κατηγορίες είναι η ανισορροπία των κλασεων, όπου έχουμε πολύ περισσότερα δειγματικά στοιχεία από την κλάση Alexa. Αυτό σημαίνει ότι ενδεχομένως ο ταξινομητής είναι biased ως προς την επιλογή/ταξινόμηση ενός δειγματικού στοιχείου στην κλάση alexa. Από το confusion matrix που εκτυπώνεται μπορεί κανείς για παράδειγμα να δει αυτή τη συμπεριφορά στην κατηγορία suppobox, όπου πολλά δειγματικά στοιχεία που πραγματικά ανήκουν στην κλάση αυτή, τελικώς ταξινομήθηκαν (λανθασμένα) στην κλάση alexa. Σε άλλες περιπτώσεις κλάσεω που τα δειγματικά στοιχεία προσομοιάζουν, ο ταξινομητής μπερδεύεται και ταξινομεί δειγματικά στοιχεία από τη μία στην άλλη.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}