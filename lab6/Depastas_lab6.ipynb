{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Lab5_RBM_DBN.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1><b>Restricted Boltzmann Machine και Deep Belief Network</b></h1>\n",
    "<p align=\"justify\">Στην συγκεκριμένη άσκηση θα μελετήσετε τον τρόπο λειτουργίας μιας <i>RBM (<a href=\"https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine\">Restricted Boltzmann Machine</a>)</i> καθώς και των <i>DBN (<a href=\"https://en.wikipedia.org/wiki/Deep_belief_network\">Deep Belief Network</a>)</i>, χρησιμοποιώντας το έτοιμο πρόγραμμα που σας δίνεται.Το συγκεκριμένο πρόγραμμα αξιοποιεί το <a href=\"https://en.wikipedia.org/wiki/MNIST_database\">dataset του <i>MNIST</i></a>, όπου είναι μια μεγάλη βάση δεδομένων με χειρόγραφα ψηφία που χρησιμοποιείται συνήθως για την εκπαίδευση διαφόρων συστημάτων επεξεργασίας εικόνας. Για την άσκηση, θα πρέπει να χρησιμοποιήσετε το αρχείο <i>mnist_original.mat</i>, το οποίο είναι διαθέσιμο από <a href=\"https://www.kaggle.com/datasets/avnishnish/mnist-original?resource=download\">εδώ</a>.</p>\n",
    "<p align=\"justify\">Μία αρκετά σημαντική εφαρμογή της <i>RBM</i> είναι η εξαγωγή χαρακτηριστικών (feature representation) από ένα dataset με σκοπό την αναπαράσταση της εισόδου (ορατοί νευρώνες) με ένα διάνυσμα μικρότερης διάστασης (κρυφοί νευρώνες). Στη συγκεκριμένη άσκηση θα συγκρίνετε την ακρίβεια ενός ταξινομητή ψηφίων με τη χρήση του αλγορίθμου <i>Logistic Regression</i>, όταν εκείνος δέχεται ως είσοδο το dataset (i) χωρίς να έχει υποστεί επεξεργασία από το <i>RBM</i>, (ii) αφου υποστεί επεξεργασία από το <i>RBM</i>, (iii) με τη χρήση <i>DBN</i>, δηλαδή δύο stacked <i>RBM</i>.</p>\n",
    "<p align=\"justify\"> Με βάση τον κώδικα που σας έχει δοθεί, καλείστε να απαντήσετε στα παρακάτω ερωτήματα:</p>\n",
    "<ul>\n",
    "<li>Να περιγράψετε σύντομα τον τρόπο λειτουργίας μιας <i>RBM</i>. Τι διαφορές έχει σε σχέση με μία <i> Μηχανή Boltzmann</i>;</li>\n",
    "<li>Ποια είναι η λογική των <i>DBN</i> και σε τι προβλήματα τα αξιοποιούμε;</li>\n",
    "<li>Να αναφέρετε τις βασικότερες εφαρμογές των <i>RBM</i> και <i>DBN</i>.</li>\n",
    "<li>Εκτός από <i>RBM</i>, τι άλλα μοντέλα μπορούν να χρησιμοποιηθούν για να δημιουργήσουν <i>DBN</i>.</li>\n",
    "<li>Συγκρίνετε τα αποτελέσματα της ταξινόμησης με τον αλγόριθμo <i>Logistic Regression</i> χωρίς τη χρήση <i>RBM</i> σε σχέση με τα αποτελέσματα της ταξινόμησης που έχει χρησιμοποιηθεί η <i>RBM</i> καθώς και με αυτή όπου χρησιμοποιούνται <i>RBM</i> και <i>DBN</i> για την εξαγωγή των χαρακτηριστικών. Τι παρατηρείτε ως προς την ακρίβεια των αποτελεσμάτων;</li>\n",
    "</ul>"
   ],
   "metadata": {
    "id": "B5q7C447X8Up"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python\n",
    "# source: https://devdreamz.com/question/905929-stacking-rbms-to-create-deep-belief-network-in-sklearn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def norm(arr):\n",
    "    arr = arr.astype(float)\n",
    "    arr -= arr.min()\n",
    "    arr /= arr.max()\n",
    "    return arr\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # load MNIST data set\n",
    "    mnist = loadmat(\"mnist-original.mat\")\n",
    "    X, Y = mnist[\"data\"].T, mnist[\"label\"][0]\n",
    "\n",
    "    # normalize inputs to 0-1 range\n",
    "    X = norm(X)\n",
    "\n",
    "    # split into train, validation, and test data sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,       Y,       test_size=10000, random_state=0)\n",
    "    X_train, X_val,  Y_train, Y_val  = train_test_split(X_train, Y_train, test_size=10000, random_state=0)\n",
    "\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # set hyperparameters\n",
    "\n",
    "    learning_rate = 0.02 \n",
    "    total_units   =  800 \n",
    "    total_epochs  =   50\n",
    "    batch_size    =  128\n",
    "\n",
    "    C = 100. # optimum for benchmark model according to sklearn docs: https://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html#sphx-glr-auto-examples-neural-networks-plot-rbm-logistic-classification-py)\n",
    "\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # construct models\n",
    "\n",
    "    # RBM\n",
    "    rbm = BernoulliRBM(n_components=total_units, learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs, verbose=1)\n",
    "\n",
    "    # \"output layer\"\n",
    "    logistic = LogisticRegression(C=C, solver='lbfgs', multi_class='multinomial', max_iter=200, verbose=1)\n",
    "\n",
    "    models = []\n",
    "    models.append(Pipeline(steps=[('logistic', clone(logistic))]))                                              # base model / benchmark\n",
    "    models.append(Pipeline(steps=[('rbm1', clone(rbm)), ('logistic', clone(logistic))]))                        # single RBM\n",
    "    models.append(Pipeline(steps=[('rbm1', clone(rbm)), ('rbm2', clone(rbm)), ('logistic', clone(logistic))]))  # RBM stack / DBN\n",
    "\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # train and evaluate models\n",
    "\n",
    "    for model in models:\n",
    "        # train\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        # evaluate using validation set\n",
    "        print(\"Model performance:\\n%s\\n\" % (\n",
    "            classification_report(Y_        val, model.predict(X_val))))"
   ],
   "metadata": {
    "id": "Z6OQ6-N8ajZJ"
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\User\\Downloads\\DSML MsC\\2nd semester\\Στοχαστικές Διεργασίες και Βελτιστοποίηση\\StochasticsLabPublic\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96       995\n",
      "         1.0       0.96      0.98      0.97      1121\n",
      "         2.0       0.90      0.90      0.90      1015\n",
      "         3.0       0.90      0.88      0.89      1033\n",
      "         4.0       0.93      0.92      0.92       976\n",
      "         5.0       0.90      0.88      0.89       884\n",
      "         6.0       0.94      0.94      0.94       999\n",
      "         7.0       0.92      0.93      0.92      1034\n",
      "         8.0       0.88      0.87      0.87       923\n",
      "         9.0       0.89      0.90      0.90      1020\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -141.39, time = 17.17s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -116.86, time = 26.82s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -107.32, time = 23.58s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -97.87, time = 23.31s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -94.00, time = 27.06s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -89.06, time = 24.65s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -85.09, time = 23.63s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -83.92, time = 22.85s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -79.13, time = 22.84s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -78.50, time = 23.62s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -77.58, time = 23.20s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -76.08, time = 22.83s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -74.85, time = 22.96s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -72.76, time = 22.80s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -71.30, time = 22.78s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -71.01, time = 23.10s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -71.78, time = 22.92s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -71.51, time = 23.84s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -69.02, time = 23.21s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -69.23, time = 23.17s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -67.78, time = 22.63s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -68.21, time = 22.74s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -67.64, time = 22.68s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -68.22, time = 22.65s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -67.42, time = 22.82s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -65.85, time = 22.77s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -67.81, time = 22.68s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -65.93, time = 22.98s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -65.79, time = 22.64s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -65.59, time = 22.72s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -64.94, time = 22.89s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -65.13, time = 22.78s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -63.95, time = 22.67s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -63.61, time = 23.12s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -63.64, time = 22.90s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -64.16, time = 22.75s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -63.64, time = 22.86s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -62.90, time = 22.66s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -63.76, time = 22.78s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -61.92, time = 22.83s\n",
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -62.22, time = 22.78s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -62.92, time = 22.74s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -61.69, time = 23.07s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -62.32, time = 22.98s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -62.97, time = 22.61s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -61.55, time = 22.69s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -62.22, time = 22.62s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -61.85, time = 22.89s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -61.63, time = 23.25s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -61.86, time = 22.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\User\\Downloads\\DSML MsC\\2nd semester\\Στοχαστικές Διεργασίες και Βελτιστοποίηση\\StochasticsLabPublic\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98       995\n",
      "         1.0       0.99      0.99      0.99      1121\n",
      "         2.0       0.96      0.97      0.97      1015\n",
      "         3.0       0.97      0.96      0.97      1033\n",
      "         4.0       0.98      0.97      0.97       976\n",
      "         5.0       0.97      0.97      0.97       884\n",
      "         6.0       0.98      0.98      0.98       999\n",
      "         7.0       0.97      0.98      0.98      1034\n",
      "         8.0       0.97      0.96      0.97       923\n",
      "         9.0       0.95      0.97      0.96      1020\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n",
      "\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -140.48, time = 16.21s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -119.74, time = 22.70s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -105.57, time = 22.65s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -97.50, time = 22.65s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -91.11, time = 23.13s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -89.20, time = 22.76s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -85.76, time = 22.85s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -84.29, time = 22.86s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -80.82, time = 22.92s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -77.91, time = 23.20s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -77.87, time = 22.77s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -76.29, time = 22.96s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -74.53, time = 23.03s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -74.13, time = 22.99s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -72.21, time = 22.95s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -71.58, time = 23.02s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -70.94, time = 22.83s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -70.00, time = 22.71s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -69.40, time = 22.88s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -69.40, time = 23.49s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -68.08, time = 22.81s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -69.37, time = 23.21s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -69.33, time = 23.02s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -69.68, time = 22.87s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -66.77, time = 23.06s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -67.00, time = 22.86s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -65.50, time = 22.78s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -65.15, time = 22.89s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -66.56, time = 22.90s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -65.85, time = 22.84s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -65.72, time = 22.82s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -63.90, time = 23.35s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -64.07, time = 22.93s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -64.05, time = 22.86s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -64.55, time = 22.81s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -63.37, time = 22.90s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -63.62, time = 22.82s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -64.36, time = 22.78s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -61.83, time = 22.89s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -62.00, time = 22.90s\n",
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -62.34, time = 23.04s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -63.71, time = 23.30s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -62.48, time = 22.76s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -61.51, time = 23.25s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -62.17, time = 22.88s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -60.65, time = 22.90s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -59.92, time = 23.05s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -61.29, time = 22.81s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -61.65, time = 22.79s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -61.67, time = 22.80s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -276.73, time = 16.27s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -255.22, time = 23.66s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -237.32, time = 23.20s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -225.49, time = 22.81s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -223.73, time = 22.96s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -219.11, time = 22.93s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -215.53, time = 22.85s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -214.46, time = 22.95s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -211.46, time = 22.91s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -207.26, time = 22.91s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -208.26, time = 24.82s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -206.93, time = 25.60s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -206.26, time = 23.21s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -204.25, time = 23.09s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -203.01, time = 23.15s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -200.50, time = 23.14s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -201.48, time = 23.29s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -201.61, time = 22.86s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -199.74, time = 22.62s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -200.96, time = 23.16s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -198.89, time = 22.80s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -197.62, time = 22.60s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -196.04, time = 23.54s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -196.20, time = 22.88s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -196.52, time = 22.61s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -198.28, time = 22.81s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -194.65, time = 22.84s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -193.62, time = 22.67s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -193.11, time = 22.71s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -194.59, time = 22.73s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -195.02, time = 22.57s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -193.87, time = 22.69s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -195.20, time = 23.28s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -193.68, time = 22.57s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -194.87, time = 23.16s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -194.67, time = 22.96s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -191.40, time = 22.52s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -192.79, time = 22.68s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -193.23, time = 22.65s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -191.51, time = 22.50s\n",
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -191.86, time = 22.66s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -193.03, time = 22.70s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -189.10, time = 22.62s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -191.36, time = 22.62s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -193.07, time = 22.58s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -191.83, time = 23.00s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -190.78, time = 22.62s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -189.28, time = 22.55s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -190.59, time = 22.44s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -190.43, time = 22.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\User\\Downloads\\DSML MsC\\2nd semester\\Στοχαστικές Διεργασίες και Βελτιστοποίηση\\StochasticsLabPublic\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99       995\n",
      "         1.0       0.99      0.99      0.99      1121\n",
      "         2.0       0.97      0.97      0.97      1015\n",
      "         3.0       0.98      0.97      0.97      1033\n",
      "         4.0       0.98      0.97      0.97       976\n",
      "         5.0       0.97      0.97      0.97       884\n",
      "         6.0       0.99      0.98      0.98       999\n",
      "         7.0       0.97      0.98      0.97      1034\n",
      "         8.0       0.97      0.96      0.96       923\n",
      "         9.0       0.96      0.96      0.96      1020\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}